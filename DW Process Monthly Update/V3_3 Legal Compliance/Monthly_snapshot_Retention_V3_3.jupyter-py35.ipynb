{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "success configuring sparkmagic livy.\n",
      "['https://qlawsbidlhe02a.ad.datalake.foc.zone:8445/gateway/dsx/livy2/v1', 'https://qlawsdl001038a.ad.datalake.foc.zone:8443/gateway/dsx/livy/v1']\n"
     ]
    }
   ],
   "source": [
    "%load_ext sparkmagic.magics\n",
    "from dsx_core_utils import proxy_util,dsxhi_util\n",
    "proxy_util.configure_proxy_livy()\n",
    "dsxhi_util.list_livy_endpoints()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "%%spark config\n",
    "{\"executorCores\": 4, \"numExecutors\": 5, \"executorMemory\": \"10g\", \n",
    " \"driverMemory\": \"8g\", \"proxyUser\": \"aliu-\", \"driverCores\": 1, \n",
    " \"conf\": {\"spark.yarn.appMasterEnv.THEANO_FLAGS\": \"base_compiledir=${PWD}/.theano\"}}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting Spark application\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<tr><th>ID</th><th>YARN Application ID</th><th>Kind</th><th>State</th><th>Spark UI</th><th>Driver log</th><th>Current session?</th></tr><tr><td>23011</td><td>application_1590030838276_75250</td><td>pyspark</td><td>idle</td><td><a target=\"_blank\" href=\"https://qlawsbidlhm02b.ad.datalake.foc.zone:8090/proxy/application_1590030838276_75250/\">Link</a></td><td><a target=\"_blank\" href=\"https://qlawsbidlhw16a.ad.datalake.foc.zone:8042/node/containerlogs/container_e499_1590030838276_75250_01_000001/aliu-\">Link</a></td><td>âœ”</td></tr></table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SparkSession available as 'spark'.\n"
     ]
    }
   ],
   "source": [
    "%spark add -s servicingdata -k -l python -u https://qlawsbidlhe02a.ad.datalake.foc.zone:8445/gateway/dsx/livy2/v1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.3.0.2.6.5.0-292"
     ]
    }
   ],
   "source": [
    "%%spark\n",
    "\n",
    "print(spark.version)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "%%spark\n",
    "\n",
    "import pyspark\n",
    "import os, sys\n",
    "\n",
    "from pyspark.sql import SparkSession\n",
    "import pyspark.sql.functions as F\n",
    "from pyspark.sql.functions import col, when, lit, countDistinct, max, min, desc\n",
    "from pyspark.sql import DataFrameStatFunctions as statFunc\n",
    "import pyspark.sql.types as T\n",
    "from functools import reduce\n",
    "\n",
    "from os.path import expanduser, join, abspath\n",
    "import time\n",
    "import pandas as pd\n",
    "\n",
    "from pyspark.ml import Pipeline, PipelineModel\n",
    "\n",
    "spark = SparkSession.builder.getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "%%spark\n",
    "\n",
    "csv_path = '/dev/projects/retention_models/csv_data/'\n",
    "#hpi_data_save_path = '/dev/projects/refi_lead_generation/datasets_old/'\n",
    "monthly_path = '/dev/projects/retention_models/monthly_snapshot/'\n",
    "monthly_prep_path = '/dev/projects/retention_models/monthly_snapshot/monthly_preprocessed/'\n",
    "actual_path = '/dev/projects/retention_models/actual_value/'\n",
    "hpi_path = '/dev/projects/retention_models/hpi/'\n",
    "\n",
    "#Refi\n",
    "model_save_path_refi = '/dev/projects/retention_models/refi_payoff/models/'\n",
    "result_path_refi = '/dev/projects/retention_models/refi_payoff/training/results/'\n",
    "\n",
    "#Pur\n",
    "model_save_path_pur = '/dev/projects/retention_models/purchase_payoff/models/'\n",
    "result_path_pur = '/dev/projects/retention_models/purchase_payoff/training/results/movermodel/'\n",
    "result_path_pur_6 = '/dev/projects/retention_models/purchase_payoff/training/results/mover_6/'\n",
    "result_path_pur_12 = '/dev/projects/retention_models/purchase_payoff/training/results/mover_12/'\n",
    "result_path_pur_all = '/dev/projects/retention_models/purchase_payoff/training/results/'\n",
    "\n",
    "#prod\n",
    "prod_pur_path = '/prod/projects/model_conformed/RocketScience/LeadGen/PurLeadGen/1.0/'\n",
    "prod_refi_path = '/prod/projects/model_conformed/RocketScience/LeadGen/RefiLeadGen/1.0/'\n",
    "file_path = '/prod/projects/model_conformed/RocketScience/LeadGen/Currentfile/'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# GCID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "%%spark\n",
    "\n",
    "df = spark.read.csv(os.path.join(csv_path, 'gcidservicingloans_20200603.csv'), header=True)  #change the file name\n",
    "\n",
    "df.write.mode('overwrite').saveAsTable('data_science_sandbox.gcidservicingloans')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# Loanlist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "%%spark\n",
    "\n",
    "# df = spark.read.csv(os.path.join(csv_path, 'servicing_loanlist_202005.csv'), header=True)  #change the file name\n",
    "\n",
    "# print(df.count())\n",
    "# df.show(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## (Before running new month) check left-portfolio data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1889579\n",
      "+-------------------+----------+\n",
      "|servicecalendardate|     ln_no|\n",
      "+-------------------+----------+\n",
      "|         2020-05-31|3368360274|\n",
      "+-------------------+----------+\n",
      "only showing top 1 row"
     ]
    }
   ],
   "source": [
    "%%spark\n",
    "\n",
    "df_list = spark.read.csv(os.path.join(csv_path, 'servicing_loanlist_202005.csv'), header=True)\n",
    "\n",
    "## right to delete loans have been removed in SQL file\n",
    "\n",
    "print(df_list.count())\n",
    "df_list.show(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1904403"
     ]
    }
   ],
   "source": [
    "%%spark\n",
    "\n",
    "df_book = spark.sql('''\n",
    "select distinct servicecalendardate, ln_no\n",
    "from data_science_sandbox.servicing_dbo_payoff_source_purchase_client_crdtrs \n",
    "where servicecalendardate = '{0}'\n",
    "and leftportfoliodate is null\n",
    "'''.format('2020-05-31'))\n",
    "\n",
    "df_book.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------+----------+\n",
      "|servicecalendardate|     ln_no|\n",
      "+-------------------+----------+\n",
      "|         2020-05-31|3308906405|\n",
      "+-------------------+----------+\n",
      "only showing top 1 row"
     ]
    }
   ],
   "source": [
    "%%spark\n",
    "\n",
    "df_book.show(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------+-------+\n",
      "|servicecalendardate|  count|\n",
      "+-------------------+-------+\n",
      "|         2020-05-31|1904403|\n",
      "+-------------------+-------+"
     ]
    }
   ],
   "source": [
    "%%spark\n",
    "\n",
    "df_book.groupBy('servicecalendardate').count().orderBy(col('servicecalendardate').desc()).show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1889579"
     ]
    }
   ],
   "source": [
    "%%spark\n",
    "\n",
    "df1 = df_book.join(df_list, on='ln_no', how='inner')\n",
    "\n",
    "df1.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## 1. Read Servicing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "%%spark\n",
    "\n",
    "def retrieve_dataset(servicedate, loanlist_file):\n",
    "    \n",
    "    spark.sql('use data_science_sandbox') \n",
    "    df_raw = spark.sql('select * from servicing_dbo_payoff_source_purchase_client_crdtrs where leftportfoliodate is null')\\\n",
    "                    .where(col('servicecalendardate') == servicedate)\n",
    "    \n",
    "    #servicing book loan list, to remove the loans already left portfolio\n",
    "    df_list = spark.read.csv(os.path.join(csv_path, loanlist_file), header=True)\n",
    "    \n",
    "    df_ser = df_raw.join(df_list, on=['servicecalendardate', 'ln_no'], how='inner').drop_duplicates()\n",
    "    \n",
    "    return df_ser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "%%spark\n",
    "\n",
    "def retrieve_dataset_dw(servicedate):\n",
    "    \n",
    "    spark.sql('use data_science_sandbox') \n",
    "    df_raw = spark.sql('select * from servicing_dbo_payoff_source_purchase_client_crdtrs')\\\n",
    "                    .where(col('servicecalendardate') == servicedate)\\\n",
    "                    .drop_duplicates()\n",
    "    \n",
    "    return df_raw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "%%spark\n",
    "\n",
    "Date = '2020-05-31'\n",
    "df_ser = retrieve_dataset(servicedate = Date, loanlist_file='servicing_loanlist_202005.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------+---------------------+------------+\n",
      "|servicecalendardate|count(DISTINCT ln_no)|count(ln_no)|\n",
      "+-------------------+---------------------+------------+\n",
      "|         2020-05-31|              1889579|     1889579|\n",
      "+-------------------+---------------------+------------+"
     ]
    }
   ],
   "source": [
    "%%spark\n",
    "\n",
    "df_ser.groupby('servicecalendardate').agg(F.countDistinct('ln_no'), F.count('ln_no')).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "903978"
     ]
    }
   ],
   "source": [
    "%%spark\n",
    "\n",
    "## match rate with experian\n",
    "df_ser.where((col('mosaichousehold').isNotNull()) & (col('mosaichousehold') != '')).count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0"
     ]
    }
   ],
   "source": [
    "%%spark\n",
    "\n",
    "## match rate with experian\n",
    "df_ser.where((col('personnum_unit').isNotNull()) & (col('personnum_unit') != '')).count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------+----------+-------------------+-------------------+--------------------+-------------------+-----------------+-----------------+-----------+--------------------+-----------+---------------+-------------------+----------+------------+-------------+-------------+-----+-----------------+----------+---------+-----------------+-----------+------------+-----------------------+-----------------------+----+--------+-----------+------------------+----------------+----------------------+-----------+---------+------------+-----------------+--------------+--------------+---------------+--------------+------------------+---------------+--------------+-----------+------------+--------+---------+--------------+-------------------+------------------+-----------+------+-------------+-------------+----------------+--------------+---------------------+----------+---------------+----------+------------------+---------+-----------------+--------------------+--------------+---------------+-----+-----+------------------+-------+---+---+------------+------------+----------+---------+-------------+---------------+-----------+----------+--------------+-----------+----------+------------+--------------+-----------+------------+--------------+---------------+-------------------+-------------+---------------+---+-----------------+---------------+---------------+----------+------------+---------+-----+--------------------+-----------+-----------------+--------------------------+-----------------+---------+--------+--------------+-----------------+--------------------------------+--------------------------+---------------------+---------------------+---------------------+--------------------------+------------+-------------+-----------------+--------------+------------------+-----------------------------+--------+-----------------+\n",
      "|servicecalendardate|     ln_no|         og_note_dt|loantypedescription|unpaidbalfirstsecond|leftportfolioreason|leftportfoliodate|investornameshort|currentcltv|loanamortizationtype|  og_mtg_am|ln_purpose_type|og_occupy_stat_type|ageinmonth|maturedmonth|times_delq_qt|ln_ann_int_rt|ln_tr|ln_monthly_pmt_am|ln_eloc_cd|orig_fico|orig_ltv_ratio_fc|pr_value_am|currentphase|numbertimeslateinlast12|numbertimesdelqinlast12| hpi|hpi_type|origdatehpi|nextmonthloanphase|issingleborrower|currenttoorighpichange|borrowerage|liveyears|buydown_flag|liveyears_missing|lostrefi_error|quarteryearkey|lengthresidence|personnum_unit|estimatedhomevalue|mosaichousehold|homebedroomcnt|p_age_31_50|p_age_50more|p_edu_hs|p_married|bedroomcnt_avm|bedroomcnt_combined|liveyears_combined|purchase_v3|payoff|overallpayoff|retentiontype|overallretention|newloanpurpose|overallnewloanpurpose|ispurchase|overallpurchase|purchase_q|purchase_q_revised|pr_zip_cd|pr_alpha_state_cd|      pr_addr_ln1_de|bo_borr_fst_nm|bo_borr_last_nm|fname|lname|prop_input_address|icstate|zip|pid|prop_landuse|prop_valcalc|prop_yrbld|yearbuilt|prop_effyrbld|prop_livingsqft|prop_bedrms|prop_baths|prop_fullbaths|prop_taxamt|prop_docyr|prop_saleamt|prop_loantoval|prop_mtgamt|prop_mtgdate|prop_mtgloancd|prop_mtgintrate|prop_mtgintratetype|prop_mtgdate2|homemarketvalue|age|lengthofresidence|homeownerrenter|estimatedincome|seniorinhh|dwellingtype|education|child|numberofchildreninhh|bookreaders|hitechenthusiasts|hobbieshomeandgardenbundle|travelenthusiasts|yearmonth|statekey|purchasepayoff|credittriggerdate|credittriggerservicecalendardate|mostrecentcredittriggerage|triggercnt1monthprior|triggercnt2monthprior|triggercnt3monthprior|purchasescore_missingfixed|payoffreason|ln_purpose_cd|og_occupy_stat_cd|p1_combinedage|end_effective_date|loan_purpose_typewebbehaviour|    gcid|servicecaldatekey|\n",
      "+-------------------+----------+-------------------+-------------------+--------------------+-------------------+-----------------+-----------------+-----------+--------------------+-----------+---------------+-------------------+----------+------------+-------------+-------------+-----+-----------------+----------+---------+-----------------+-----------+------------+-----------------------+-----------------------+----+--------+-----------+------------------+----------------+----------------------+-----------+---------+------------+-----------------+--------------+--------------+---------------+--------------+------------------+---------------+--------------+-----------+------------+--------+---------+--------------+-------------------+------------------+-----------+------+-------------+-------------+----------------+--------------+---------------------+----------+---------------+----------+------------------+---------+-----------------+--------------------+--------------+---------------+-----+-----+------------------+-------+---+---+------------+------------+----------+---------+-------------+---------------+-----------+----------+--------------+-----------+----------+------------+--------------+-----------+------------+--------------+---------------+-------------------+-------------+---------------+---+-----------------+---------------+---------------+----------+------------+---------+-----+--------------------+-----------+-----------------+--------------------------+-----------------+---------+--------+--------------+-----------------+--------------------------------+--------------------------+---------------------+---------------------+---------------------+--------------------------+------------+-------------+-----------------+--------------+------------------+-----------------------------+--------+-----------------+\n",
      "|         2020-05-31|3306692986|2012-04-20 00:00:00|   Conventional w/o|           121394.17|               null|             null|             FNMA|       null|               Fixed|140800.0000|   Cashout Refi|  Primary Residence|      null|        null|         null|     .0525000|  360|        1819.3700|         N|     null|            0.800|248055.0000|            |                   null|                   null|null|        |       null|                  |               0|                  null|       null|     null|            |             null|          null|        Q12020|           14.0|           2.0|          265500.0|            B07|           4.0|          2|           0|       0|        1|              |                   |              null|       null|  null|         null|             |                |              |                     |      null|           null|      null|              null|    77379|               TX|5607    EDGEWOOD ...|    CHRISTOPHE|        JACKSON|     |     |                  |       |   |   |            |            |          |         |             |               |           |          |              |           |          |            |              |           |            |              |               |                   |             |               |   |                 |               |               |          |            |         |     |                    |           |                 |                          |                 |     null|        |          null|                 |                      2020-05-31|                       370|                    0|                    0|                    0|                      null|            |            6|                1|           E48|                  |         REFINANCE/EQUITY ...|52020844|         20200531|\n",
      "+-------------------+----------+-------------------+-------------------+--------------------+-------------------+-----------------+-----------------+-----------+--------------------+-----------+---------------+-------------------+----------+------------+-------------+-------------+-----+-----------------+----------+---------+-----------------+-----------+------------+-----------------------+-----------------------+----+--------+-----------+------------------+----------------+----------------------+-----------+---------+------------+-----------------+--------------+--------------+---------------+--------------+------------------+---------------+--------------+-----------+------------+--------+---------+--------------+-------------------+------------------+-----------+------+-------------+-------------+----------------+--------------+---------------------+----------+---------------+----------+------------------+---------+-----------------+--------------------+--------------+---------------+-----+-----+------------------+-------+---+---+------------+------------+----------+---------+-------------+---------------+-----------+----------+--------------+-----------+----------+------------+--------------+-----------+------------+--------------+---------------+-------------------+-------------+---------------+---+-----------------+---------------+---------------+----------+------------+---------+-----+--------------------+-----------+-----------------+--------------------------+-----------------+---------+--------+--------------+-----------------+--------------------------------+--------------------------+---------------------+---------------------+---------------------+--------------------------+------------+-------------+-----------------+--------------+------------------+-----------------------------+--------+-----------------+\n",
      "only showing top 1 row"
     ]
    }
   ],
   "source": [
    "%%spark\n",
    "\n",
    "df_ser.show(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+-------+\n",
      "|p_age_31_50|  count|\n",
      "+-----------+-------+\n",
      "|          1| 294620|\n",
      "|          6|    115|\n",
      "|          3|  47265|\n",
      "|          5|   1077|\n",
      "|          4|   8843|\n",
      "|          2| 180819|\n",
      "|          0|1356840|\n",
      "+-----------+-------+"
     ]
    }
   ],
   "source": [
    "%%spark\n",
    "\n",
    "df_ser.groupby('p_age_31_50').count().show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## 2. Preprocess Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### (1) Selected columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "%%spark\n",
    "\n",
    "df_new = df_ser.select('servicecalendardate', 'og_note_dt', 'ln_no',\n",
    "                        'loantypedescription', 'unpaidbalfirstsecond', 'loanamortizationtype', 'og_mtg_am',\n",
    "                        'ln_purpose_type', 'og_occupy_stat_type',\n",
    "                        'ln_ann_int_rt', 'ln_tr', 'ln_monthly_pmt_am', 'ln_eloc_cd',\n",
    "                        'orig_ltv_ratio_fc', 'pr_value_am', 'investornameshort',\n",
    "                        'issingleborrower', 'liveyears', 'pr_zip_cd',\n",
    "                        'lengthresidence', 'personnum_unit', 'estimatedhomevalue', 'mosaichousehold', 'homebedroomcnt',\n",
    "                        'p1_combinedage', 'p_age_31_50', 'p_age_50more', 'p_edu_hs', 'p_married', 'quarteryearkey',\n",
    "                        'mostrecentcredittriggerage', 'triggercnt1monthprior', 'triggercnt2monthprior', 'triggercnt3monthprior'\n",
    "                       )\n",
    "\n",
    "#'gcid'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "source": [
    "### (2) Market Data\n",
    "\n",
    "Lock2close should update the market rate daily. Check the latest update date to see if there are values in the data lake."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+\n",
      "|max(dateid)|\n",
      "+-----------+\n",
      "| 2020-06-09|\n",
      "+-----------+"
     ]
    }
   ],
   "source": [
    "%%spark\n",
    "\n",
    "t1 = spark.sql('select * from lock2close_raw_access.dbo_marketdatafact_l2c_orc')\n",
    "t1.agg(F.max('dateid')).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "%%spark\n",
    "\n",
    "def retrieve_marketdatafact():\n",
    "    \"\"\"Retrieve market interest rates from DL\"\"\"\n",
    "    \n",
    "    df = spark.sql('select * from lock2close_raw_access.dbo_marketdatafact_l2c_orc')\\\n",
    "                .where(F.to_date(col('dateid'), 'yyyy-MM-dd') >= '2015-12-01')\\\n",
    "                .withColumn('yearmonth', col('dateid').substr(1, 7))\n",
    "    \n",
    "    df_market = df.groupby('yearmonth')\\\n",
    "                    .agg(F.min('currentfannie30yryield').alias('fannie30_min'),\n",
    "                         F.min('currentfannie15yryield').alias('fannie15_min'),\n",
    "                         F.min('currentginny30yryield').alias('ginny30_min'))\n",
    "    \n",
    "    return F.broadcast(df_market)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "%%spark\n",
    "\n",
    "df_market_agg = retrieve_marketdatafact()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+------------+------------+-----------+\n",
      "|yearmonth|fannie30_min|fannie15_min|ginny30_min|\n",
      "+---------+------------+------------+-----------+\n",
      "|  2020-06|       1.618|       1.042|       1.45|\n",
      "+---------+------------+------------+-----------+"
     ]
    }
   ],
   "source": [
    "%%spark\n",
    "\n",
    "df_market_agg.filter(col('yearmonth') == '2020-06').show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+------------+------------+-----------+\n",
      "|yearmonth|fannie30_min|fannie15_min|ginny30_min|\n",
      "+---------+------------+------------+-----------+\n",
      "|  2020-05|       1.539|        1.08|       1.34|\n",
      "|  2020-03|       1.468|       0.913|      1.384|\n",
      "|  2020-04|       1.522|       1.094|      1.137|\n",
      "+---------+------------+------------+-----------+"
     ]
    }
   ],
   "source": [
    "%%spark\n",
    "\n",
    "## check if every month has value\n",
    "df_market_agg.where(F.col('yearmonth').isin('2020-05', '2020-03', '2020-04')).show(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### (*) Update HPI (Once necessary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+----+-------+------+--------------------+----+----+\n",
      "|zip|year|quarter| index|                type| _c5| _c6|\n",
      "+---+----+-------+------+--------------------+----+----+\n",
      "|010|1995|      1|100.00|Native 3-Digit ZI...|null|null|\n",
      "+---+----+-------+------+--------------------+----+----+\n",
      "only showing top 1 row"
     ]
    }
   ],
   "source": [
    "%%spark\n",
    "\n",
    "hpi_raw = spark.read.csv(csv_path + 'hpi_2020q1.csv', header=True)\n",
    "hpi_raw.show(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+----+-------+------+--------------------+----+----+-----+\n",
      "|zip|year|quarter| index|                type| _c5| _c6|month|\n",
      "+---+----+-------+------+--------------------+----+----+-----+\n",
      "|010|1995|      1|100.00|Native 3-Digit ZI...|null|null|    1|\n",
      "+---+----+-------+------+--------------------+----+----+-----+\n",
      "only showing top 1 row"
     ]
    }
   ],
   "source": [
    "%%spark\n",
    "\n",
    "expr_mon1 = when(col('quarter')=='1', '1')\\\n",
    "                .otherwise(\n",
    "                    when(col('quarter')=='2', '4')\\\n",
    "                        .otherwise(\n",
    "                            when(col('quarter')=='3', '7')\\\n",
    "                                .otherwise('10')))\n",
    "    \n",
    "expr_mon2 = when(col('quarter')=='1', '2')\\\n",
    "                .otherwise(\n",
    "                    when(col('quarter')=='2', '5')\\\n",
    "                        .otherwise(\n",
    "                            when(col('quarter')=='3', '8')\\\n",
    "                                .otherwise('11')))\n",
    "\n",
    "expr_mon3 = when(col('quarter')=='1', '3')\\\n",
    "                .otherwise(\n",
    "                    when(col('quarter')=='2', '6')\\\n",
    "                        .otherwise(\n",
    "                            when(col('quarter')=='3', '9')\\\n",
    "                                .otherwise('12')))\n",
    "\n",
    "raw1 = hpi_raw.withColumn('month', expr_mon1)\n",
    "raw2 = hpi_raw.withColumn('month', expr_mon2)\n",
    "raw3 = hpi_raw.withColumn('month', expr_mon3)\n",
    "\n",
    "hpi_new = raw1.union(raw2).union(raw3)\n",
    "\n",
    "hpi_new.show(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "%%spark\n",
    "\n",
    "hpi_new.write.parquet(hpi_path + 'hpi.parquet', mode='overwrite')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+----+-------+------+--------------------+----+----+-----+\n",
      "|zip|year|quarter| index|                type| _c5| _c6|month|\n",
      "+---+----+-------+------+--------------------+----+----+-----+\n",
      "|013|2011|      4|184.15|      MSA/MSAD Index|null|null|   10|\n",
      "|011|2011|      4|183.14|Native 3-Digit ZI...|null|null|   10|\n",
      "+---+----+-------+------+--------------------+----+----+-----+\n",
      "only showing top 2 rows"
     ]
    }
   ],
   "source": [
    "%%spark\n",
    "\n",
    "hpi = spark.read.parquet(hpi_path + 'hpi.parquet')\n",
    "\n",
    "hpi.sort(desc('year')).sort(desc('quarter')).show(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+----+-------+------+--------------------+----+----+-----+\n",
      "|zip|year|quarter| index|                type| _c5| _c6|month|\n",
      "+---+----+-------+------+--------------------+----+----+-----+\n",
      "|010|2020|      1|221.25|Native 3-Digit ZI...|null|null|    2|\n",
      "|011|2020|      1|234.46|Native 3-Digit ZI...|null|null|    2|\n",
      "+---+----+-------+------+--------------------+----+----+-----+\n",
      "only showing top 2 rows"
     ]
    }
   ],
   "source": [
    "%%spark\n",
    "\n",
    "hpi.where( (col('year') == 2020) & (col('quarter') == 1) ).show(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### (3) HPI\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "%%spark\n",
    "\n",
    "  ## Loads the HPI based on 3-digit zip (for estimating home value)## Loads \n",
    "\n",
    "def preprocess_hpi(pullmonth, usemax=True):\n",
    "    \n",
    "    # If it's for current month, set usemax=True, which means the most recent as the current value.\n",
    "    # If it's for historical data, set usemax=False, which means the pull month is the current value.\n",
    "       \n",
    "    expr_padded_month = F.lpad(col('month'), 2, '0')\n",
    "    \n",
    "    df_hpi = spark.read.parquet(hpi_path + 'hpi.parquet')\\\n",
    "                    .withColumn('hpi_yearmonth', F.concat(col('year'), F.lit('-'), expr_padded_month))\\\n",
    "                    .withColumn('hpi_zip', F.lpad(col('zip'), 3, '0'))\n",
    "    \n",
    "    df_hpi_max_date = df_hpi.groupby('hpi_zip').agg(F.max('hpi_yearmonth').alias('yearmonth_max'))\\\n",
    "                            .withColumn('yearmonth_pull', F.lit(pullmonth))\n",
    "    \n",
    "    if not usemax:\n",
    "        df_hpi_curr_date = df_hpi_max_date.withColumnRenamed('yearmonth_pull', 'hpi_yearmonth')\n",
    "    else:\n",
    "        df_hpi_curr_date = df_hpi_max_date.withColumnRenamed('yearmonth_max', 'hpi_yearmonth')\n",
    "        \n",
    "    df_hpi_current = df_hpi.join(df_hpi_curr_date, on=['hpi_yearmonth', 'hpi_zip'], how='inner')\\\n",
    "                        .withColumnRenamed('index', 'hpi_current')\\\n",
    "                        .select('hpi_zip', 'hpi_current')\n",
    "    \n",
    "    df_hpi = df_hpi.join(df_hpi_current, on='hpi_zip', how='left')\\\n",
    "                .select('hpi_zip', 'hpi_yearmonth', 'index', 'hpi_current')\\\n",
    "                .withColumnRenamed('index', 'hpi_og')\n",
    "    \n",
    "    df_hpi_avg = df_hpi.groupby('hpi_yearmonth')\\\n",
    "                        .agg(F.avg('hpi_og').cast('float').alias('hpi_avg'), \n",
    "                             F.avg('hpi_current').cast('float').alias('hpi_current_avg'))\\\n",
    "                        .withColumnRenamed('hpi_yearmonth', 'hpi_yearmonth_avg')\n",
    "\n",
    "    return F.broadcast(df_hpi), F.broadcast(df_hpi_avg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "%%spark\n",
    "\n",
    "df_hpi, df_hpi_avg = preprocess_hpi(pullmonth='2020-06', usemax=True)\n",
    "\n",
    "#historical\n",
    "#df_hpi, df_hpi_avg = preprocess_hpi(pullmonth='2016-06', usemax=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-------------+------+-----------+\n",
      "|hpi_zip|hpi_yearmonth|hpi_og|hpi_current|\n",
      "+-------+-------------+------+-----------+\n",
      "|    124|      2020-03|285.08|     285.08|\n",
      "|    447|      2020-03|168.86|     168.86|\n",
      "+-------+-------------+------+-----------+\n",
      "only showing top 2 rows"
     ]
    }
   ],
   "source": [
    "%%spark\n",
    "\n",
    "df_hpi.sort(desc('hpi_yearmonth')).show(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------+---------+---------------+\n",
      "|hpi_yearmonth_avg|  hpi_avg|hpi_current_avg|\n",
      "+-----------------+---------+---------------+\n",
      "|          1999-10|121.27708|      240.72694|\n",
      "|          2013-05|178.59459|      240.72694|\n",
      "|          2009-07|183.20718|      240.72694|\n",
      "+-----------------+---------+---------------+\n",
      "only showing top 3 rows"
     ]
    }
   ],
   "source": [
    "%%spark\n",
    "\n",
    "df_hpi_avg.show(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### (4) Update FICO table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "#%%spark\n",
    "\n",
    "#df_fico = spark.read.csv(csv_path + 'servicing_fico_20190903.csv', header=True)\\\n",
    "#                .select('ln_no', col('orig_fico').cast('int'))\n",
    "    \n",
    "#df_fico.write.mode('overwrite').saveAsTable('data_science_sandbox.servicing_fico_aug2019_backfiled')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3907106"
     ]
    }
   ],
   "source": [
    "%%spark\n",
    "\n",
    "df_fico = spark.read.csv(csv_path + 'servicing_fico_20200603.csv', header=True)\\\n",
    "                .select('ln_no', col('orig_fico').cast('int'))\n",
    "df_fico.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "%%spark\n",
    "\n",
    "df_fico.write.mode('overwrite').saveAsTable('data_science_sandbox.servicing_fico')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3907106\n",
      "+----------+---------+\n",
      "|     ln_no|orig_fico|\n",
      "+----------+---------+\n",
      "|3389560443|      650|\n",
      "+----------+---------+\n",
      "only showing top 1 row"
     ]
    }
   ],
   "source": [
    "%%spark\n",
    "\n",
    "fico_check = spark.sql('select * from data_science_sandbox.servicing_fico')\n",
    "\n",
    "print(fico_check.count())\n",
    "fico_check.show(1)\n",
    "## count should be increasing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+-------+\n",
      "|  insertdt|  count|\n",
      "+----------+-------+\n",
      "|2020-06-03|  83299|\n",
      "|2020-05-04|  81001|\n",
      "|2020-04-03|  68198|\n",
      "|2020-03-03|  56059|\n",
      "|2020-02-03|  57400|\n",
      "|2020-01-03|  61346|\n",
      "|2019-12-02|  61868|\n",
      "|2019-11-05|  63390|\n",
      "|2019-10-04|  52721|\n",
      "|2019-09-03|  48327|\n",
      "|2019-08-05|  28421|\n",
      "|2019-07-12| 537306|\n",
      "|2018-12-03|  29413|\n",
      "|2018-11-01|  33836|\n",
      "|2018-10-01|  30261|\n",
      "|2018-09-04|  36346|\n",
      "|2018-08-01|  32714|\n",
      "|2018-07-06|  32328|\n",
      "|2018-06-26|2512872|\n",
      "+----------+-------+"
     ]
    }
   ],
   "source": [
    "%%spark\n",
    "\n",
    "spark.read.csv(csv_path + 'servicing_fico_20200603.csv', header=True).groupBy('insertdt').count().orderBy(desc('insertdt')).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### (5) Combine all tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "%%spark\n",
    "\n",
    "def combine_tables(df, mdf = df_market_agg, df_hpi = df_hpi, df_hpi_avg=df_hpi_avg):\n",
    "    \n",
    "    df = df.withColumn('yearmonth', col('servicecalendardate').substr(1, 7))\\\n",
    "            .withColumn('og_yearmonth', col('og_note_dt').substr(1, 7))\\\n",
    "            .withColumn('zip3', col('pr_zip_cd').substr(1, 3))\n",
    "    \n",
    "    #Join market data\n",
    "    df = df.join(mdf, on='yearmonth', how = 'left')\n",
    "    \n",
    "    #Add FICO to the table\n",
    "    df_fico = spark.sql('select * from data_science_sandbox.servicing_fico')\n",
    "    df = df.join(df_fico, on='ln_no', how='left')\n",
    "    \n",
    "    #Join the hpi data\n",
    "    df = df.join(df_hpi, (df.og_yearmonth == df_hpi.hpi_yearmonth) & (df.zip3 == df_hpi.hpi_zip), how='left')\\\n",
    "            .withColumnRenamed('index', 'hpi_og')\n",
    "            \n",
    "    #Use the average to manipulate NULL hpi           \n",
    "    df = df.join(df_hpi_avg, df.og_yearmonth == df_hpi_avg.hpi_yearmonth_avg, how='left')\n",
    "    \n",
    "    #HPI columns and HPI change\n",
    "    expr_hpi_og = F.when(F.col('hpi_og').isNull(), F.col('hpi_avg')).otherwise(F.col('hpi_og'))\n",
    "\n",
    "    expr_hpi_curr = F.when(F.col('hpi_current').isNull(), F.col('hpi_current_avg')).otherwise(F.col('hpi_current'))\n",
    "\n",
    "    expr_hpi_change = F.when(F.col('hpi_avg').isNull(), 1.0).otherwise(expr_hpi_curr/expr_hpi_og)\n",
    "\n",
    "    df = df.withColumn('hpi_og_exp', expr_hpi_og)\\\n",
    "            .withColumn('hpi_curr_exp', expr_hpi_curr)\\\n",
    "            .withColumn('hpi_change_exp', expr_hpi_change)\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "%%spark\n",
    "\n",
    "df_all = combine_tables(df_new)\n",
    "\n",
    "#df_all.show(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "%%spark\n",
    "\n",
    "#Save a copy for quick analysis\n",
    "df_all.write.parquet(os.path.join(monthly_path, 'servicing_df_all_may20_20200610.parquet'), mode='overwrite')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### (6). Preprocess Data Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "%%spark\n",
    "\n",
    "df_all = spark.read.parquet(os.path.join(monthly_path, 'servicing_df_all_may20_20200610.parquet'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "%%spark\n",
    "\n",
    "def preprocess_dataset(df):\n",
    "    \n",
    "    ##credit trigger\n",
    "    expr_ct_age = F.when(F.col('mostrecentcredittriggerage').isNull(), 0)\\\n",
    "                            .otherwise(\n",
    "                                F.when(F.col('mostrecentcredittriggerage').isin(['NULL', 'null', '0']), 0)\\\n",
    "                                    .otherwise(F.col('mostrecentcredittriggerage') + 1\n",
    "                                            )\n",
    "                                    )\n",
    "    expr_ct_1_mo = F.when(F.col('triggercnt1monthprior').isNull(), '0')\\\n",
    "                            .otherwise(\n",
    "                                F.when(F.col('triggercnt1monthprior').isin(['NULL', 'null', '0']), '0')\\\n",
    "                                    .otherwise(\n",
    "                                        F.when(F.col('triggercnt1monthprior') > 1, '1')\\\n",
    "                                            .otherwise(F.col('triggercnt1monthprior')).cast('string')\n",
    "                                            )\n",
    "                                    )\n",
    "                                  \n",
    "    expr_ct_2_mo = F.when(F.col('triggercnt2monthprior').isNull(), '0')\\\n",
    "                            .otherwise(\n",
    "                                F.when(F.col('triggercnt2monthprior').isin(['NULL', 'null', '0']), '0')\\\n",
    "                                    .otherwise(\n",
    "                                        F.when(F.col('triggercnt2monthprior') > 2, '2')\\\n",
    "                                            .otherwise(F.col('triggercnt2monthprior')).cast('string')\n",
    "                                            )\n",
    "                                    )\n",
    "        \n",
    "    expr_ct_3_mo = F.when(F.col('triggercnt3monthprior').isNull(), '0')\\\n",
    "                            .otherwise(\n",
    "                                F.when(F.col('triggercnt3monthprior').isin(['NULL', 'null', '0']), '0')\\\n",
    "                                    .otherwise(\n",
    "                                        F.when(F.col('triggercnt3monthprior') > 3, '3')\\\n",
    "                                            .otherwise(F.col('triggercnt3monthprior')).cast('string')\n",
    "                                            )\n",
    "                                    )\n",
    "    \n",
    "    ##Experian\n",
    "    expr_home_value = F.when(F.col('EstimatedHomeValue').isNull(), 271225.)\\\n",
    "                            .otherwise(\n",
    "                                F.when(F.col('EstimatedHomeValue').isin(['NULL', 'null', '0']), 271225.)\\\n",
    "                                    .otherwise(F.col('EstimatedHomeValue')\n",
    "                                            )\n",
    "                                    )\n",
    "        \n",
    "    expr_age_31_50 = F.when(F.col('p_age_31_50').isNull(), 0)\\\n",
    "                        .otherwise(\n",
    "                            F.when(F.col('p_age_31_50').isin(['null', 'NULL']), 0)\\\n",
    "                                .otherwise(F.col('p_age_31_50').cast('int')))\n",
    "    \n",
    "    expr_edu_hs = F.when(F.col('p_edu_hs').isNull(), 0)\\\n",
    "                        .otherwise(\n",
    "                            F.when(F.col('p_edu_hs').isin(['null', 'NULL']), 0)\\\n",
    "                                .otherwise(F.col('p_edu_hs').cast('int')))\n",
    "    \n",
    "    expr_married = F.when(F.col('p_married').isNull(), 0)\\\n",
    "                        .otherwise(\n",
    "                            F.when(F.col('p_married').isin(['null', 'NULL']), 0)\\\n",
    "                                .otherwise(F.col('p_married').cast('int')))\n",
    "        \n",
    "    expr_bedroomcnt = F.when(F.col('homebedroomcnt').isNull(), 3)\\\n",
    "                            .otherwise(\n",
    "                                F.when(F.col('homebedroomcnt').isin(['NULL', 'null', '0']), 3)\\\n",
    "                                    .otherwise(\n",
    "                                        F.when(F.col('homebedroomcnt').isin(['1', '2', '3', '4', '5']), F.col('homebedroomcnt').cast('int'))\\\n",
    "                                            .otherwise(6)\n",
    "                                            )\n",
    "                                    )\n",
    "                             \n",
    "    expr_person_per_room = F.when(F.col('personnum_unit').isNull(), 3 / expr_bedroomcnt)\\\n",
    "                                .otherwise(\n",
    "                                    F.when(F.col('personnum_unit').isin(['null', 'NULL', '0']), 3 / expr_bedroomcnt)\\\n",
    "                                        .otherwise(F.col('personnum_unit') / expr_bedroomcnt)\n",
    "                                )\n",
    "    \n",
    "    #Different mosaic groups from the one in mover model!!\n",
    "    expr_mosaicgroup = F.when(F.col('mosaichousehold').isin(['Null', 'null']), 'other')\\\n",
    "                            .otherwise(F.col('mosaichousehold').substr(0, 1))\n",
    "        \n",
    "    expr_mosaicgroup_refi_clust = F.when(expr_mosaicgroup.isin(['B', 'H', 'Q']), 'BHQ')\\\n",
    "                                   .otherwise(\n",
    "                                       F.when(expr_mosaicgroup.isin(['A', 'C', 'G']), 'ACG')\\\n",
    "                                           .otherwise(\n",
    "                                               F.when(expr_mosaicgroup.isin(['D', 'E', 'F', 'J', 'K']), 'DEFJK')\\\n",
    "                                                   .otherwise(\n",
    "                                                       F.when(expr_mosaicgroup.isin(['I', 'L']), 'IL')\\\n",
    "                                                           .otherwise(\n",
    "                                                               F.when(expr_mosaicgroup.isin(['M', 'N', 'O', 'P', 'R', 'S']), 'MNOPRS')\\\n",
    "                                                                   .otherwise('other')\n",
    "                                                           )\n",
    "                                                   )\n",
    "                                               )\n",
    "                                   )\n",
    "        \n",
    "    expr_mosaicgroup_pur_clust = F.when(expr_mosaicgroup.isin(['A', 'B']), 'AB')\\\n",
    "                                   .otherwise(\n",
    "                                       F.when(expr_mosaicgroup.isin(['C', 'D', 'E']), 'CDE')\\\n",
    "                                           .otherwise(\n",
    "                                               F.when(expr_mosaicgroup.isin(['F', 'G']), 'FG')\\\n",
    "                                                   .otherwise(\n",
    "                                                       F.when(expr_mosaicgroup.isin(['I', 'J']), 'IJ')\\\n",
    "                                                           .otherwise('other')\n",
    "                                                   )\n",
    "                                            )\n",
    "                                   )    \n",
    "        \n",
    "    ##Market Rate\n",
    "    expr_rate_spread_min = F.when(F.col('ln_ann_int_rt').isNull(), 0.0)\\\n",
    "                                .otherwise(\n",
    "                                    F.when(F.col('ln_ann_int_rt').isin(['null', 'NULL']), 0.0)\\\n",
    "                                        .otherwise(F.when(F.col('loantypedescription') == 'CONV', \n",
    "                                                         F.when(F.col('ln_tr') == '360', \n",
    "                                                                F.col('ln_ann_int_rt')*100 - F.col('fannie30_min'))\\\n",
    "                                                                .otherwise(F.col('ln_ann_int_rt')*100 - F.col('fannie15_min'))\n",
    "                                                         )\\\n",
    "                                                   .otherwise(\n",
    "                                                       F.when(F.col('loantypedescription').isin(['FHA', 'VA']), \n",
    "                                                              F.col('ln_ann_int_rt')*100 - F.col('ginny30_min'))\\\n",
    "                                                               .otherwise(F.col('ln_ann_int_rt')*100 - F.col('fannie30_min')))\n",
    "                                                   )\n",
    "                                            )\n",
    "\n",
    "    # This is only for Mover V3 and before \n",
    "    expr_rate_spread_min_pur = F.when(F.col('ln_ann_int_rt').isNull(), 0.0)\\\n",
    "                                .otherwise(\n",
    "                                    F.when(F.col('ln_ann_int_rt').isin(['null', 'NULL']), 0.0)\\\n",
    "                                        .otherwise(F.when(F.col('loantypedescription') == 'CONV', \n",
    "                                                         F.when(F.col('ln_tr') == '360', \n",
    "                                                                 F.col('fannie30_min') - F.col('ln_ann_int_rt')*100)\\\n",
    "                                                                .otherwise(F.col('fannie15_min') - F.col('ln_ann_int_rt')*100)\n",
    "                                                         )\\\n",
    "                                                   .otherwise(\n",
    "                                                       F.when(F.col('loantypedescription').isin(['FHA', 'VA']), \n",
    "                                                               F.col('ginny30_min') - F.col('ln_ann_int_rt')*100)\\\n",
    "                                                               .otherwise(F.col('fannie15_min')) - F.col('ln_ann_int_rt')*100)\n",
    "                                                   )\n",
    "                                            )\n",
    "\n",
    "    expr_borrowerage_group = F.when(F.col('p1_combinedage').isNull(), 'median')\\\n",
    "                                .otherwise(\n",
    "                                    F.when(F.col('p1_combinedage').isin(['Null', 'null']), 'median')\\\n",
    "                                        .otherwise(\n",
    "                                            F.when(F.col('p1_combinedage').substr(2, 2).cast('double') > 40.0, 'old')\\\n",
    "                                                .otherwise(\n",
    "                                                    F.when(F.col('p1_combinedage').substr(2, 2).cast('double') < 25.0, 'young')\\\n",
    "                                                        .otherwise('median')\n",
    "                                                )\n",
    "                                       )\n",
    "                                )\n",
    "    \n",
    "    ##Servicing Data       \n",
    "    expr_loan_type = F.when(F.col('loantypedescription').isin(['FHA', 'VA']), F.lower(F.col('loantypedescription')))\\\n",
    "                        .otherwise('conv')\n",
    "    \n",
    "    expr_ageinmon = F.when(F.col('og_note_dt').isNull(), 83)\\\n",
    "                        .otherwise(\n",
    "                            F.when(F.col('og_note_dt').isin(['null', 'NULL']), 83)\\\n",
    "                                .otherwise(F.months_between(F.col('servicecalendardate'), F.col('og_note_dt')))\n",
    "                        )        \n",
    "    \n",
    "    #Currentcltv (use HPI change)\n",
    "    expr_og_mtg_am = when(col('og_mtg_am').isNull(), 173200.)\\\n",
    "                        .otherwise(\n",
    "                            when(col('og_mtg_am').isin(['NULL', 'null']), 173200.)\n",
    "                                .otherwise(\n",
    "                                    col('og_mtg_am').cast('double')\n",
    "                                    )\n",
    "                            )\n",
    "\n",
    "    expr_og_homevalue = when((col('pr_value_am').isNotNull()) & (~col('pr_value_am').isin(['null', 'NULL', '0', 0])), col('pr_value_am'))\\\n",
    "                            .otherwise(\n",
    "                                when(col('orig_ltv_ratio_fc').isNull(), 0.)\\\n",
    "                                    .otherwise(\n",
    "                                        when(col('orig_ltv_ratio_fc').isin(['null', 'NULL', '0', 0]), 0.)\\\n",
    "                                            .otherwise(expr_og_mtg_am / col('orig_ltv_ratio_fc'))\n",
    "                                    )\n",
    "                            )\n",
    "\n",
    "    expr_currentcltv_cal = when(col('unpaidbalfirstsecond').isNull(), 0.)\\\n",
    "                                .otherwise(\n",
    "                                    when(col('unpaidbalfirstsecond').isin(['null', 'NULL', '0']), 0.)\\\n",
    "                                        .otherwise(100 * col('unpaidbalfirstsecond') / (expr_og_homevalue * col('hpi_change_exp')))\n",
    "                                )\n",
    "\n",
    "    expr_currentcltv = when(expr_currentcltv_cal.isNull(), 70.8)\\\n",
    "                    .otherwise(\n",
    "                        when(expr_currentcltv_cal > 150, 150)\\\n",
    "                            .otherwise(\n",
    "                                when(expr_currentcltv_cal < 10, 10)\\\n",
    "                                    .otherwise(expr_currentcltv_cal)\n",
    "                            )\n",
    "                    )\n",
    "    \n",
    "    expr_orig_fico = F.when(F.col('orig_fico').isNull(), 735)\\\n",
    "                            .otherwise(\n",
    "                                F.when(F.col('orig_fico').isin(['null', 'NULL']), 735)\\\n",
    "                                    .otherwise(\n",
    "                                        F.when(F.col('orig_fico') > 850, 850)\\\n",
    "                                            .otherwise(\n",
    "                                                F.when(F.col('orig_fico') < 500, 500)\\\n",
    "                                                    .otherwise(F.col('orig_fico').cast('int')\n",
    "                                        )\n",
    "                                    )\n",
    "                                )\n",
    "                            )\n",
    "    \n",
    "    #Liveyears\n",
    "    expr_liveyears = F.when(F.col('lengthresidence').isNotNull(), F.col('lengthresidence'))\\\n",
    "                        .otherwise(\n",
    "                            F.when(F.col('liveyears').isNotNull(), F.col('liveyears'))\\\n",
    "                                .otherwise(expr_ageinmon/12)\n",
    "                            )\n",
    "    \n",
    "    expr_liveyears_short = F.when(expr_liveyears <= 4., expr_liveyears).otherwise(0.)\n",
    "    \n",
    "    expr_liveyears_long = F.when(expr_liveyears > 4, expr_liveyears).otherwise(0.)\n",
    "                                  \n",
    "    expr_liveyears_grp = F.when(expr_liveyears <= 4, 1.).otherwise(0.)                             \n",
    "        \n",
    "    expr_ln_purpose_type = F.when(F.col('ln_purpose_type').isin(['NULL', 'null', 'other']), 'refinance')\\\n",
    "                                .otherwise(F.lower(F.col('ln_purpose_type')))\n",
    "    \n",
    "    expr_og_occupy_stat_type = F.when(F.col('og_occupy_stat_type').isin(['NULL', 'null', 'other']), 'investment property')\\\n",
    "                            .otherwise(F.lower(F.col('og_occupy_stat_type')))\n",
    "\n",
    "    expr_issingleborrower = F.when(F.col('issingleborrower').isNull(), 0)\\\n",
    "                                .otherwise(\n",
    "                                    F.when(F.col('issingleborrower').isin(['NULL', 'null']), 0)\n",
    "                                        .otherwise(F.col('issingleborrower')))\n",
    "    \n",
    "    expr_ln_tr = F.when(F.col('ln_tr').isNull(), 360)\\\n",
    "                    .otherwise(\n",
    "                        F.when(F.col('ln_tr').isin(['NULL', 'null']), 360)\\\n",
    "                            .otherwise(F.col('ln_tr')))\n",
    "\n",
    "        \n",
    "    df = df.withColumn('ct_age_exp', expr_ct_age)\\\n",
    "        .withColumn('ct_1_exp', expr_ct_1_mo)\\\n",
    "        .withColumn('ct_2_exp', expr_ct_2_mo)\\\n",
    "        .withColumn('ct_3_exp', expr_ct_3_mo)\\\n",
    "        .withColumn('home_value_exp', expr_home_value)\\\n",
    "        .withColumn('p_edu_hs_exp', expr_edu_hs)\\\n",
    "        .withColumn('personnum_per_room_exp', expr_person_per_room)\\\n",
    "        .withColumn('mosaic_group_refi_exp', expr_mosaicgroup_refi_clust)\\\n",
    "        .withColumn('mosaic_group_pur_exp', expr_mosaicgroup_pur_clust)\\\n",
    "        .withColumn('ratespread_min_exp', expr_rate_spread_min)\\\n",
    "        .withColumn('ratespread_min_pur_exp', expr_rate_spread_min_pur)\\\n",
    "        .withColumn('loantypedescription_exp', expr_loan_type)\\\n",
    "        .withColumn('ageinmon_exp', expr_ageinmon)\\\n",
    "        .withColumn('og_mtg_am_exp', expr_og_mtg_am)\\\n",
    "        .withColumn('currentcltv_exp', expr_currentcltv)\\\n",
    "        .withColumn('orig_fico_exp', expr_orig_fico)\\\n",
    "        .withColumn('LiveYears_short_exp', expr_liveyears_short)\\\n",
    "        .withColumn('LiveYears_long_exp', expr_liveyears_long)\\\n",
    "        .withColumn('LiveYears_grp_exp', expr_liveyears_grp)\\\n",
    "        .withColumn('ln_purpose_type_exp', expr_ln_purpose_type)\\\n",
    "        .withColumn('og_occupy_stat_type_exp', expr_og_occupy_stat_type)\\\n",
    "        .withColumn('issingleborrower_exp', expr_issingleborrower)\\\n",
    "        .withColumn('ln_tr_exp', expr_ln_tr)\\\n",
    "        .withColumn('loanamortizationtype', F.lower(F.col('loanamortizationtype')))\\\n",
    "        .withColumn('ln_ann_int_rt', F.col('ln_ann_int_rt').cast('double'))\\\n",
    "        .withColumn('p_31_50_exp', expr_age_31_50)\\\n",
    "        .withColumn('p_married_exp', expr_married)\\\n",
    "        .withColumn('borrowerage_bucket', expr_borrowerage_group)\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "%%spark\n",
    "\n",
    "def save_preprocess(df, filename):\n",
    "    \n",
    "    df_prep = preprocess_dataset(df)\n",
    "    \n",
    "    df1 = df_prep.select('servicecalendardate', 'ln_no', 'og_note_dt',\n",
    "                           'ct_age_exp', 'ct_1_exp', 'ct_2_exp', 'ct_3_exp',\n",
    "                           'home_value_exp', 'p_edu_hs_exp',\n",
    "                           'personnum_per_room_exp', 'mosaic_group_refi_exp', 'mosaic_group_pur_exp',\n",
    "                           'ratespread_min_exp', 'ratespread_min_pur_exp', 'ln_ann_int_rt',\n",
    "                           'loantypedescription_exp', 'loanamortizationtype', 'ageinmon_exp',\n",
    "                           'og_mtg_am_exp', 'currentcltv_exp', 'orig_fico_exp',\n",
    "                           'LiveYears_short_exp', 'LiveYears_long_exp', 'LiveYears_grp_exp',\n",
    "                           'ln_purpose_type_exp', 'ln_purpose_type', 'og_occupy_stat_type_exp', 'issingleborrower_exp',\n",
    "                           'ln_tr_exp', 'investornameshort').drop_duplicates()\n",
    "    \n",
    "    df1.write.parquet(monthly_prep_path + filename, mode='overwrite')\n",
    "    \n",
    "# select('gcid')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "%%spark\n",
    "\n",
    "#def save_preprocess_old(df, filename):\n",
    "    \n",
    "#    df_prep = preprocess_dataset(df)\n",
    "    \n",
    "#    df1 = df_prep.select('servicecalendardate', 'ln_no', 'og_note_dt',\n",
    "#                           'ct_age_exp', 'ct_1_exp', 'ct_2_exp', 'ct_3_exp',\n",
    "#                           'home_value_exp', 'p_edu_hs_exp', 'p_31_50_exp', 'p_married_exp', 'borrowerage_bucket',\n",
    "#                           'personnum_per_room_exp', 'mosaic_group_refi_exp', 'mosaic_group_pur_exp',\n",
    "#                           'ratespread_min_exp', 'ratespread_min_pur_exp', 'ln_ann_int_rt',\n",
    "#                           'loantypedescription_exp', 'loanamortizationtype', 'ageinmon_exp',\n",
    "#                           'og_mtg_am_exp', 'currentcltv_exp', 'orig_fico_exp',\n",
    "#                           'LiveYears_short_exp', 'LiveYears_long_exp', 'LiveYears_grp_exp',\n",
    "#                           'ln_purpose_type_exp', 'ln_purpose_type', 'og_occupy_stat_type_exp', 'issingleborrower_exp',\n",
    "#                           'ln_tr_exp', 'investornameshort').drop_duplicates()\n",
    "    \n",
    "#    df1.write.parquet(monthly_prep_path + filename, mode='overwrite')\n",
    "    \n",
    "# select('gcid')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "%%spark\n",
    "\n",
    "save_preprocess(df_all, 'monthly_preprocessed_202005.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "%%spark\n",
    "\n",
    "#save_preprocess_old(df_all, 'monthly_preprocessed_202005_old.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1889579\n",
      "+-------------------+----------+-------------------+----------+--------+--------+--------+--------------+------------+----------------------+---------------------+--------------------+------------------+----------------------+-------------+-----------------------+--------------------+------------+-------------+------------------+-------------+-------------------+------------------+-----------------+-------------------+---------------+-----------------------+--------------------+---------+-----------------+\n",
      "|servicecalendardate|     ln_no|         og_note_dt|ct_age_exp|ct_1_exp|ct_2_exp|ct_3_exp|home_value_exp|p_edu_hs_exp|personnum_per_room_exp|mosaic_group_refi_exp|mosaic_group_pur_exp|ratespread_min_exp|ratespread_min_pur_exp|ln_ann_int_rt|loantypedescription_exp|loanamortizationtype|ageinmon_exp|og_mtg_am_exp|   currentcltv_exp|orig_fico_exp|LiveYears_short_exp|LiveYears_long_exp|LiveYears_grp_exp|ln_purpose_type_exp|ln_purpose_type|og_occupy_stat_type_exp|issingleborrower_exp|ln_tr_exp|investornameshort|\n",
      "+-------------------+----------+-------------------+----------+--------+--------+--------+--------------+------------+----------------------+---------------------+--------------------+------------------+----------------------+-------------+-----------------------+--------------------+------------+-------------+------------------+-------------+-------------------+------------------+-----------------+-------------------+---------------+-----------------------+--------------------+---------+-----------------+\n",
      "|         2020-05-31|3305853525|2012-02-29 00:00:00|       624|       0|       0|       0|      347900.0|           2|                   0.5|                DEFJK|                  IJ|             2.035|                 -5.41|      0.03375|                    fha|               fixed|        99.0|     152308.0|15.514876703444484|          791|                0.0|              12.0|              0.0|          refinance|      Refinance|      primary residence|                   1|      180|             GNMA|\n",
      "+-------------------+----------+-------------------+----------+--------+--------+--------+--------------+------------+----------------------+---------------------+--------------------+------------------+----------------------+-------------+-----------------------+--------------------+------------+-------------+------------------+-------------+-------------------+------------------+-----------------+-------------------+---------------+-----------------------+--------------------+---------+-----------------+\n",
      "only showing top 1 row"
     ]
    }
   ],
   "source": [
    "%%spark\n",
    "\n",
    "preprocessed_month_data = spark.read.parquet(monthly_prep_path + 'monthly_preprocessed_202005.parquet')\n",
    "\n",
    "print(preprocessed_month_data.count())\n",
    "preprocessed_month_data.show(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "%%spark\n",
    "\n",
    "#preprocessed_month_data_old = spark.read.parquet(monthly_prep_path + 'monthly_preprocessed_202005_old.parquet')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## 4. Mover Refi Model Scoring"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### (1) Read Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "%%spark\n",
    "\n",
    "refi_model_pipeline_lr = PipelineModel.load(path = model_save_path_refi+'refiV1_4_LR_20200513')\n",
    "refi_model_pipeline_rf = PipelineModel.load(path = model_save_path_refi+'refiV1_4_RF_20200513')\n",
    "refi_model_pipeline_gbt = PipelineModel.load(path = model_save_path_refi+'refiV1_4_GBT_20200513')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "%%spark\n",
    "\n",
    "## compare with the previous model\n",
    "\n",
    "#refi_model_pipeline_lr_old = PipelineModel.load(path = model_save_path_refi+'refiV1_3_LR_20190716')\n",
    "#refi_model_pipeline_rf_old = PipelineModel.load(path = model_save_path_refi+'refiV1_3_RF_20190716')\n",
    "#refi_model_pipeline_gbt_old = PipelineModel.load(path = model_save_path_refi+'refiV1_3_GBT_20190716')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### (2) Rename columns to score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "%%spark\n",
    "\n",
    "preprocessed_month_data_refi = preprocessed_month_data             \n",
    "\n",
    "#.withColumnRenamed('ratespread_min_exp', 'ratespread_min_refi_exp')\n",
    "#.withColumnRenamed('mosaic_group_refi_exp', 'mosaic_group_exp')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### (3) Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "%%spark\n",
    "\n",
    "def fullMonthPrediction_refi(df):\n",
    "    \n",
    "    _scoreUdf = F.udf(lambda v: float(v[1]), T.DoubleType())\n",
    "    \n",
    "    predictionsLR = refi_model_pipeline_lr.transform(df)\n",
    "    pred_df_lr = predictionsLR.withColumn('pred', _scoreUdf(predictionsLR['probability']))\\\n",
    "                                .select('ln_no', 'og_note_dt', 'investornameshort', 'loanamortizationtype', \n",
    "                                        col('loantypedescription_exp').alias('loantypedescription'),\n",
    "                                        col('ln_tr_exp').alias('loan_term'), \n",
    "                                        col('ageinmon_exp').alias('loan_age'), \n",
    "                                        col('currentcltv_exp').alias('currentcltv'),\n",
    "                                        col('ln_ann_int_rt').alias('loan_interest_rate'), \n",
    "                                        col('pred').alias('logRegProb'))\n",
    "    \n",
    "    predictionsRF = refi_model_pipeline_rf.transform(df)\n",
    "    pred_df_rf = predictionsRF.withColumn('pred', _scoreUdf(predictionsRF['probability']))\\\n",
    "                               .select('ln_no', col('pred').alias('randForProb'))\n",
    "\n",
    "    predictionsGBT = refi_model_pipeline_gbt.transform(df)\n",
    "    pred_df_gbt = predictionsGBT.withColumn('pred', _scoreUdf(predictionsGBT['probability']))\\\n",
    "                                .select('ln_no', col('pred').alias('gbtProb'))\n",
    "\n",
    "    final_join = pred_df_lr.join(pred_df_rf, on='ln_no', how='left')\\\n",
    "                           .join(pred_df_gbt, on='ln_no', how='left')\n",
    "     \n",
    "    final_join = final_join.dropDuplicates()\n",
    "    \n",
    "    return final_join"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "%%spark\n",
    "\n",
    "#def fullMonthPrediction_refi_old(df):\n",
    "    \n",
    "#    _scoreUdf = F.udf(lambda v: float(v[1]), T.DoubleType())\n",
    "    \n",
    "#    predictionsLR = refi_model_pipeline_lr_old.transform(df)\n",
    "#    pred_df_lr = predictionsLR.withColumn('pred', _scoreUdf(predictionsLR['probability']))\\\n",
    "#                                .select('ln_no', 'og_note_dt', 'investornameshort', 'loanamortizationtype', \n",
    "#                                        col('loantypedescription_exp').alias('loantypedescription'),\n",
    "#                                        col('ln_tr_exp').alias('loan_term'), \n",
    "#                                        col('ageinmon_exp').alias('loan_age'), \n",
    "#                                        col('currentcltv_exp').alias('currentcltv'),\n",
    "#                                        col('ln_ann_int_rt').alias('loan_interest_rate'), \n",
    "#                                        col('pred').alias('logRegProb'))\n",
    "    \n",
    "#    predictionsRF = refi_model_pipeline_rf_old.transform(df)\n",
    "#    pred_df_rf = predictionsRF.withColumn('pred', _scoreUdf(predictionsRF['probability']))\\\n",
    "#                               .select('ln_no', col('pred').alias('randForProb'))\n",
    "\n",
    "#    predictionsGBT = refi_model_pipeline_gbt_old.transform(df)\n",
    "#    pred_df_gbt = predictionsGBT.withColumn('pred', _scoreUdf(predictionsGBT['probability']))\\\n",
    "#                                .select('ln_no', col('pred').alias('gbtProb'))\n",
    "\n",
    "#    final_join = pred_df_lr.join(pred_df_rf, on='ln_no', how='left')\\\n",
    "#                           .join(pred_df_gbt, on='ln_no', how='left')\n",
    "     \n",
    "#    final_join = final_join.dropDuplicates()\n",
    "    \n",
    "#    return final_join"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "%%spark\n",
    "\n",
    "def dedup_result_pred_refi(pred_df):\n",
    "    \n",
    "    pred_df_dedup = pred_df.groupby(['ln_no', 'og_note_dt', 'loantypedescription', 'loanamortizationtype', 'investornameshort']).mean()\n",
    "    \n",
    "    oldcols = pred_df_dedup.schema.names\n",
    "    newcols = ['ln_no', 'og_note_dt', 'loantypedescription', 'loanamortizationtype', 'investornameshort',\\\n",
    "               'loan_term', 'loan_age', 'currentcltv', 'loan_interest_rate',\\\n",
    "               'logRegProb', 'randForProb', 'gbtProb']\n",
    "    pred_df_dedup = reduce(lambda pred_df_dedup, idx: pred_df_dedup.withColumnRenamed(oldcols[idx], newcols[idx]), range(len(oldcols)), pred_df_dedup)\n",
    "    \n",
    "    return pred_df_dedup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "%%spark\n",
    "\n",
    "def save_csv_refi(df_prep, filename, result_path = result_path_refi):\n",
    "    \n",
    "    pred = fullMonthPrediction_refi(df_prep)\n",
    "    dedup = dedup_result_pred_refi(pred)\n",
    "    \n",
    "    dedup.coalesce(1).write.csv(result_path + filename, header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "%%spark\n",
    "\n",
    "#def save_csv_refi_old(df_prep, filename, result_path = result_path_refi):\n",
    "#    \n",
    "#    pred = fullMonthPrediction_refi_old(df_prep)\n",
    "#    dedup = dedup_result_pred_refi(pred)\n",
    "#    \n",
    "#    dedup.coalesce(1).write.csv(result_path + filename, header=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "#### 2018"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "%%spark\n",
    "\n",
    "#2018.1\n",
    "pred201801_refi = fullMonthPrediction_refi(preprocessed_month_data_refi)\n",
    "pred201801_dedup_refi = dedup_result_pred_refi(pred201801_refi)\\\n",
    "                            .select('ln_no', 'logRegProb', 'randForProb', 'gbtProb')\n",
    "\n",
    "save_results_csv_refi(pred201801_dedup_refi, 'pred_refiV1_jan18_20190409.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "%%spark\n",
    "\n",
    "#2018.2\n",
    "pred201802_refi = fullMonthPrediction_refi(preprocessed_month_data_refi)\n",
    "pred201802_dedup_refi = dedup_result_pred_refi(pred201802_refi)\\\n",
    "                            .select('ln_no', 'logRegProb', 'randForProb', 'gbtProb')\n",
    "\n",
    "save_results_csv_refi(pred201802_dedup_refi, 'pred_refiV1_feb18_20190409.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "%%spark\n",
    "\n",
    "#2018.4\n",
    "pred201804_refi = fullMonthPrediction_refi(preprocessed_month_data_refi)\n",
    "pred201804_dedup_refi = dedup_result_pred_refi(pred201804_refi)\\\n",
    "                            .select('ln_no', 'logRegProb', 'randForProb', 'gbtProb')\n",
    "\n",
    "save_results_csv_refi(pred201804_dedup_refi, 'pred_refiV1_apr18_20190409.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "%%spark\n",
    "\n",
    "#2018.5\n",
    "pred201805_refi = fullMonthPrediction_refi(preprocessed_month_data_refi)\n",
    "pred201805_dedup_refi = dedup_result_pred_refi(pred201805_refi)\\\n",
    "                            .select('ln_no', 'logRegProb', 'randForProb', 'gbtProb')\n",
    "\n",
    "save_results_csv_refi(pred201805_dedup_refi, 'pred_refiV1_may18_20190409.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "%%spark\n",
    "\n",
    "#2018.6\n",
    "pred201806_refi = fullMonthPrediction_refi(preprocessed_month_data_refi)\n",
    "pred201806_dedup_refi = dedup_result_pred_refi(pred201806_refi)\\\n",
    "                            .select('ln_no', 'logRegProb', 'randForProb', 'gbtProb')\n",
    "\n",
    "save_results_csv_refi(pred201806_dedup_refi, 'pred_refiV1_jun18_20190409.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "%%spark\n",
    "\n",
    "#2018.7\n",
    "pred201807_refi = fullMonthPrediction_refi(preprocessed_month_data_refi)\n",
    "pred201807_dedup_refi = dedup_result_pred_refi(pred201807_refi)\\\n",
    "                            .select('ln_no', 'logRegProb', 'randForProb', 'gbtProb')\n",
    "\n",
    "save_results_csv_refi(pred201807_dedup_refi, 'pred_refiV1_jul18_20190409.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "%%spark\n",
    "\n",
    "#2018.8\n",
    "pred201808_refi = fullMonthPrediction_refi(preprocessed_month_data_refi)\n",
    "pred201808_dedup_refi = dedup_result_pred_refi(pred201808_refi)\\\n",
    "                            .select('ln_no', 'logRegProb', 'randForProb', 'gbtProb')\n",
    "\n",
    "save_results_csv_refi(pred201808_dedup_refi, 'pred_refiV1_aug18_20190409.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "%%spark\n",
    "\n",
    "#2018.12\n",
    "pred201812_refi = fullMonthPrediction_refi(preprocessed_month_data_refi)\n",
    "pred201812_dedup_refi = dedup_result_pred_refi(pred201812_refi)\n",
    "\n",
    "save_results_csv_refi(pred201812_dedup_refi, 'pred_refiV1_dec18_20190205.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "#### 2019"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "%%spark\n",
    "\n",
    "#2019.1\n",
    "pred201901_refi = fullMonthPrediction_refi(preprocessed_month_data_refi)\n",
    "pred201901_dedup_refi = dedup_result_pred_refi(pred201901_refi)\n",
    "\n",
    "save_results_csv_refi(pred201901_dedup_refi, 'pred_refiV1_jan19_20190215.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "%%spark\n",
    "\n",
    "#2019.2\n",
    "pred201902_refi = fullMonthPrediction_refi(preprocessed_month_data_refi)\n",
    "pred201902_dedup_refi = dedup_result_pred_refi(pred201902_refi)\n",
    "\n",
    "save_results_csv_refi(pred201902_dedup_refi, 'pred_refiV1_feb19_20190305.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "%%spark\n",
    "\n",
    "#2019.3\n",
    "pred201903_refi = fullMonthPrediction_refi(preprocessed_month_data_refi)\n",
    "pred201903_dedup_refi = dedup_result_pred_refi(pred201903_refi)\n",
    "\n",
    "save_results_csv_refi(pred201903_dedup_refi, 'pred_refiV1_mar19_20190409.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "%%spark\n",
    "\n",
    "#2019.4\n",
    "pred201904_refi = fullMonthPrediction_refi(preprocessed_month_data_refi)\n",
    "pred201904_dedup_refi = dedup_result_pred_refi(pred201904_refi)\n",
    "\n",
    "save_results_csv_refi(pred201904_dedup_refi, 'pred_refiV1_apr19_20190507.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "%%spark\n",
    "\n",
    "#2019.5\n",
    "pred201905_refi = fullMonthPrediction_refi(preprocessed_month_data_refi)\n",
    "pred201905_dedup_refi = dedup_result_pred_refi(pred201905_refi)\n",
    "\n",
    "save_results_csv_refi(pred201905_dedup_refi, 'pred_refiV1_2_may19_20190610.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "%%spark\n",
    "\n",
    "#2019.6\n",
    "save_csv_refi(preprocessed_month_data_refi, 'pred_refiV1_3_jun19_20190717.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "%%spark\n",
    "\n",
    "#2019.7\n",
    "save_csv_refi(preprocessed_month_data_refi, 'pred_refiV1_3_jul19_20190805.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "%%spark\n",
    "\n",
    "#2019.8\n",
    "save_csv_refi(preprocessed_month_data_refi, 'pred_refiV1_3_aug19_20190904.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "%%spark\n",
    "\n",
    "#2019.9\n",
    "save_csv_refi(preprocessed_month_data_refi, 'pred_refiV1_3_sep19_20191004.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "%%spark\n",
    "\n",
    "#2019.10\n",
    "save_csv_refi(preprocessed_month_data_refi, 'pred_refiV1_3_oct19_20191105.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "%%spark\n",
    "\n",
    "#2019.11\n",
    "save_csv_refi(preprocessed_month_data_refi, 'pred_refiV1_3_nov19_20191203.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### 2020"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "%%spark\n",
    "\n",
    "#2020.01\n",
    "save_csv_refi(preprocessed_month_data_refi, 'pred_refiV1_3_jan20_20200203.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "%%spark\n",
    "\n",
    "#2020.02\n",
    "save_csv_refi(preprocessed_month_data_refi, 'pred_refiV1_3_feb20_20200305.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "%%spark\n",
    "\n",
    "#2020.03\n",
    "save_csv_refi(preprocessed_month_data_refi, 'pred_refiV1_3_mar20_20200406.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "%%spark\n",
    "\n",
    "#2020.04\n",
    "save_csv_refi(preprocessed_month_data_refi, 'pred_refiV1_3_apr20_20200505.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "%%spark\n",
    "\n",
    "#2020.05\n",
    "save_csv_refi(preprocessed_month_data_refi, 'pred_refiV1_4_may20_20200610.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "%%spark\n",
    "\n",
    "##2020.05\n",
    "#save_csv_refi_old(preprocessed_month_data_old, 'pred_refiV1_3_may20_20200610.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------+----------+-------------------+----------+--------+--------+--------+--------------+------------+----------------------+---------------------+--------------------+------------------+----------------------+-------------+-----------------------+--------------------+------------+-------------+------------------+-------------+-------------------+------------------+-----------------+-------------------+---------------+-----------------------+--------------------+---------+-----------------+\n",
      "|servicecalendardate|     ln_no|         og_note_dt|ct_age_exp|ct_1_exp|ct_2_exp|ct_3_exp|home_value_exp|p_edu_hs_exp|personnum_per_room_exp|mosaic_group_refi_exp|mosaic_group_pur_exp|ratespread_min_exp|ratespread_min_pur_exp|ln_ann_int_rt|loantypedescription_exp|loanamortizationtype|ageinmon_exp|og_mtg_am_exp|   currentcltv_exp|orig_fico_exp|LiveYears_short_exp|LiveYears_long_exp|LiveYears_grp_exp|ln_purpose_type_exp|ln_purpose_type|og_occupy_stat_type_exp|issingleborrower_exp|ln_tr_exp|investornameshort|\n",
      "+-------------------+----------+-------------------+----------+--------+--------+--------+--------------+------------+----------------------+---------------------+--------------------+------------------+----------------------+-------------+-----------------------+--------------------+------------+-------------+------------------+-------------+-------------------+------------------+-----------------+-------------------+---------------+-----------------------+--------------------+---------+-----------------+\n",
      "|         2020-05-31|3305853525|2012-02-29 00:00:00|       624|       0|       0|       0|      347900.0|           2|                   0.5|                DEFJK|                  IJ|             2.035|                 -5.41|      0.03375|                    fha|               fixed|        99.0|     152308.0|15.514876703444484|          791|                0.0|              12.0|              0.0|          refinance|      Refinance|      primary residence|                   1|      180|             GNMA|\n",
      "+-------------------+----------+-------------------+----------+--------+--------+--------+--------------+------------+----------------------+---------------------+--------------------+------------------+----------------------+-------------+-----------------------+--------------------+------------+-------------+------------------+-------------+-------------------+------------------+-----------------+-------------------+---------------+-----------------------+--------------------+---------+-----------------+\n",
      "only showing top 1 row"
     ]
    }
   ],
   "source": [
    "%%spark\n",
    "\n",
    "preprocessed_month_data_refi.show(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## 5. Mover Purchase Model Scoring"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### (1) Read Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "%%spark\n",
    "\n",
    "pur_model_pipeline_lr = PipelineModel.load(path = model_save_path_pur + 'MoverV3_3_LR_20200513')\n",
    "pur_model_pipeline_rf = PipelineModel.load(path = model_save_path_pur + 'MoverV3_3_RF_20200513')\n",
    "pur_model_pipeline_gbt = PipelineModel.load(path = model_save_path_pur + 'MoverV3_3_GBT_20200513')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### (2) Rename columns to score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "%%spark\n",
    "\n",
    "preprocessed_month_data_pur = preprocessed_month_data\n",
    "\n",
    "#.withColumn('loantype_exp', F.upper(F.col('loantypedescription_exp')))\\\n",
    "#.withColumnRenamed('ratespread_min_pur_exp', 'ratecompare_exp')\\\n",
    "#.withColumnRenamed('mosaic_group_pur_exp', 'mosaic_group_exp')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### (3) Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "%%spark\n",
    "\n",
    "def fullMonthPrediction_pur(df):\n",
    "    \n",
    "    _scoreUdf = F.udf(lambda v: float(v[1]), T.DoubleType())\n",
    "    \n",
    "    predictionsLR = pur_model_pipeline_lr.transform(df)\n",
    "    pred_df_lr = predictionsLR.withColumn('pred', _scoreUdf(predictionsLR['probability']))\\\n",
    "                                .select('ln_no', col('pred').alias('logRegProb'))\n",
    "    \n",
    "    predictionsRF = pur_model_pipeline_rf.transform(df)\n",
    "    pred_df_rf = predictionsRF.withColumn('pred', _scoreUdf(predictionsRF['probability']))\\\n",
    "                               .select('ln_no', col('pred').alias('randForProb'))\n",
    "\n",
    "    predictionsGBT = pur_model_pipeline_gbt.transform(df)\n",
    "    pred_df_gbt = predictionsGBT.withColumn('pred', _scoreUdf(predictionsGBT['probability']))\\\n",
    "                                .select('ln_no', col('pred').alias('gbtProb'))\n",
    "\n",
    "    final_join = pred_df_lr.join(pred_df_rf, on='ln_no', how='left')\\\n",
    "                           .join(pred_df_gbt, on='ln_no', how='left')\n",
    "     \n",
    "    final_join = final_join.dropDuplicates()\n",
    "    \n",
    "    return final_join"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "%%spark\n",
    "\n",
    "def dedup_result_pred_pur(pred_df):\n",
    "    \n",
    "    pred_df_dedup = pred_df.groupby('ln_no')\\\n",
    "                            .agg(F.avg('logRegProb').alias('logRegProb'),\n",
    "                                 F.avg('randForProb').alias('randForProb'),\n",
    "                                 F.avg('gbtProb').alias('gbtProb')\n",
    "                            )\n",
    "\n",
    "    return pred_df_dedup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "%%spark\n",
    "\n",
    "def save_csv_pur(df_prep, filename, result_path = result_path_pur):\n",
    "    \n",
    "    pred = fullMonthPrediction_pur(df_prep)\n",
    "    dedup = dedup_result_pred_pur(pred)\n",
    "    \n",
    "    dedup.coalesce(1).write.csv(result_path + filename, header=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "#### 2018"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "%%spark\n",
    "\n",
    "#2018.1\n",
    "pred201801_pur = fullMonthPrediction_pur(preprocessed_month_data_pur)\n",
    "pred201801_dedup_pur = dedup_result_pred_pur(pred201801_pur)\n",
    "\n",
    "save_results_csv_pur(pred201801_dedup_pur, 'pred_Mover_CT3_jan18_20190409.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "%%spark\n",
    "\n",
    "#2018.2\n",
    "pred201802_pur = fullMonthPrediction_pur(preprocessed_month_data_pur)\n",
    "pred201802_dedup_pur = dedup_result_pred_pur(pred201802_pur)\n",
    "\n",
    "save_results_csv_pur(pred201802_dedup_pur, 'pred_Mover_CT3_feb18_20190409.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "%%spark\n",
    "\n",
    "#2018.4\n",
    "pred201804_pur = fullMonthPrediction_pur(preprocessed_month_data_pur)\n",
    "pred201804_dedup_pur = dedup_result_pred_pur(pred201804_pur)\n",
    "\n",
    "save_results_csv_pur(pred201804_dedup_pur, 'pred_Mover_CT3_apr18_20190409.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "%%spark\n",
    "\n",
    "#2018.5\n",
    "pred201805_pur = fullMonthPrediction_pur(preprocessed_month_data_pur)\n",
    "pred201805_dedup_pur = dedup_result_pred_pur(pred201805_pur)\n",
    "\n",
    "save_results_csv_pur(pred201805_dedup_pur, 'pred_Mover_CT3_may18_20190409.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "%%spark\n",
    "\n",
    "#2018.11\n",
    "pred201811_pur = fullMonthPrediction_pur(preprocessed_month_data_pur)\n",
    "pred201811_dedup_pur = dedup_result_pred_pur(pred201811_pur)\n",
    "\n",
    "save_results_csv_pur(pred201811_dedup_pur, 'pred_Mover_CT3_nov18_20190409.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "%%spark\n",
    "\n",
    "#2018.12\n",
    "pred201812_pur = fullMonthPrediction_pur(preprocessed_month_data_pur)\n",
    "pred201812_dedup_pur = dedup_result_pred_pur(pred201812_pur)\n",
    "\n",
    "save_results_csv_pur(pred201812_dedup_pur, 'pred_Mover_CT3_dec18_20190131.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "#### 2019"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "%%spark\n",
    "\n",
    "#2019.1\n",
    "pred201901_pur = fullMonthPrediction_pur(preprocessed_month_data_pur)\n",
    "pred201901_dedup_pur = dedup_result_pred_pur(pred201901_pur)\n",
    "\n",
    "save_results_csv_pur(pred201901_dedup_pur, 'pred_Mover_CT3_jan19_20190215.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "%%spark\n",
    "\n",
    "#2019.2\n",
    "pred201902_pur = fullMonthPrediction_pur(preprocessed_month_data_pur)\n",
    "pred201902_dedup_pur = dedup_result_pred_pur(pred201902_pur)\n",
    "\n",
    "save_results_csv_pur(pred201902_dedup_pur, 'pred_Mover_CT3_feb19_20190305.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "%%spark\n",
    "\n",
    "#2019.3\n",
    "pred201903_pur = fullMonthPrediction_pur(preprocessed_month_data_pur)\n",
    "pred201903_dedup_pur = dedup_result_pred_pur(pred201903_pur)\n",
    "\n",
    "save_results_csv_pur(pred201903_dedup_pur, 'pred_Mover_CT3_mar19_20190409.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "%%spark\n",
    "\n",
    "#2019.4\n",
    "pred201904_pur = fullMonthPrediction_pur(preprocessed_month_data_pur)\n",
    "pred201904_dedup_pur = dedup_result_pred_pur(pred201904_pur)\n",
    "\n",
    "save_results_csv_pur(pred201904_dedup_pur, 'pred_Mover_CT3_apr19_20190507.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "%%spark\n",
    "\n",
    "#2019.5\n",
    "pred201905_pur = fullMonthPrediction_pur(preprocessed_month_data_pur)\n",
    "pred201905_dedup_pur = dedup_result_pred_pur(pred201905_pur)\n",
    "\n",
    "save_results_csv_pur(pred201905_dedup_pur, 'pred_Mover_CT3_may19_20190610.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "%%spark\n",
    "\n",
    "#2019.6\n",
    "pred201906_pur = fullMonthPrediction_pur(preprocessed_month_data_pur)\n",
    "pred201906_dedup_pur = dedup_result_pred_pur(pred201906_pur)\n",
    "\n",
    "save_results_csv_pur(pred201906_dedup_pur, 'pred_Mover_CT3_june19_20190708.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "%%spark\n",
    "\n",
    "#2019.7\n",
    "save_csv_pur(preprocessed_month_data_pur, 'pred_MoverV3_2_jul19_20190805.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "%%spark\n",
    "\n",
    "#2019.8\n",
    "save_csv_pur(preprocessed_month_data_pur, 'pred_MoverV3_2_aug19_20190904.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "%%spark\n",
    "\n",
    "#2019.9\n",
    "save_csv_pur(preprocessed_month_data_pur, 'pred_MoverV3_2_sep19_20191004.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "%%spark\n",
    "\n",
    "#2019.10\n",
    "save_csv_pur(preprocessed_month_data_pur, 'pred_MoverV3_2_oct19_20191105.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "%%spark\n",
    "\n",
    "#2019.11\n",
    "save_csv_pur(preprocessed_month_data_pur, 'pred_MoverV3_2_nov19_20191203.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### 2020"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "%%spark\n",
    "\n",
    "#2020.01\n",
    "save_csv_pur(preprocessed_month_data_pur, 'pred_MoverV3_2_jan20_20200203.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "%%spark\n",
    "\n",
    "#2020.02\n",
    "save_csv_pur(preprocessed_month_data_pur, 'pred_MoverV3_2_feb20_20200305.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "%%spark\n",
    "\n",
    "#2020.03\n",
    "save_csv_pur(preprocessed_month_data_pur, 'pred_MoverV3_2_mar20_20200406.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "%%spark\n",
    "\n",
    "#2020.04\n",
    "save_csv_pur(preprocessed_month_data_pur, 'pred_MoverV3_2_apr20_20200505.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "%%spark\n",
    "\n",
    "#2020.05\n",
    "save_csv_pur(preprocessed_month_data_pur, 'pred_MoverV3_3_may20_20200610.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## 6. Expanded Mover Purchase Models Scoring"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### (1). Read Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "%%spark\n",
    "\n",
    "# 3-6 Months \n",
    "model_pipeline_lr_6 = PipelineModel.load(path = model_save_path_pur + 'Mover_3to6_V1_1_LR_20200515')\n",
    "model_pipeline_rf_6 = PipelineModel.load(path = model_save_path_pur + 'Mover_3to6_V1_1_RF_20200515')\n",
    "model_pipeline_gbt_6 = PipelineModel.load(path = model_save_path_pur + 'Mover_3to6_V1_1_GBT_20200515')\n",
    "\n",
    "# 6-12 Months\n",
    "model_pipeline_lr_12 = PipelineModel.load(path = model_save_path_pur + 'Mover_6to12_V1_1_LR_20200516')\n",
    "model_pipeline_rf_12 = PipelineModel.load(path = model_save_path_pur + 'Mover_6to12_V1_1_RF_20200516')\n",
    "model_pipeline_gbt_12 = PipelineModel.load(path = model_save_path_pur + 'Mover_6to12_V1_1_GBT_20200516')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### (2). Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- servicecalendardate: date (nullable = true)\n",
      " |-- ln_no: string (nullable = true)\n",
      " |-- og_note_dt: timestamp (nullable = true)\n",
      " |-- ct_age_exp: integer (nullable = true)\n",
      " |-- ct_1_exp: string (nullable = true)\n",
      " |-- ct_2_exp: string (nullable = true)\n",
      " |-- ct_3_exp: string (nullable = true)\n",
      " |-- home_value_exp: double (nullable = true)\n",
      " |-- p_edu_hs_exp: integer (nullable = true)\n",
      " |-- personnum_per_room_exp: double (nullable = true)\n",
      " |-- mosaic_group_refi_exp: string (nullable = true)\n",
      " |-- mosaic_group_pur_exp: string (nullable = true)\n",
      " |-- ratespread_min_exp: double (nullable = true)\n",
      " |-- ratespread_min_pur_exp: double (nullable = true)\n",
      " |-- ln_ann_int_rt: double (nullable = true)\n",
      " |-- loantypedescription_exp: string (nullable = true)\n",
      " |-- loanamortizationtype: string (nullable = true)\n",
      " |-- ageinmon_exp: double (nullable = true)\n",
      " |-- og_mtg_am_exp: double (nullable = true)\n",
      " |-- currentcltv_exp: double (nullable = true)\n",
      " |-- orig_fico_exp: integer (nullable = true)\n",
      " |-- LiveYears_short_exp: double (nullable = true)\n",
      " |-- LiveYears_long_exp: double (nullable = true)\n",
      " |-- LiveYears_grp_exp: double (nullable = true)\n",
      " |-- ln_purpose_type_exp: string (nullable = true)\n",
      " |-- ln_purpose_type: string (nullable = true)\n",
      " |-- og_occupy_stat_type_exp: string (nullable = true)\n",
      " |-- issingleborrower_exp: integer (nullable = true)\n",
      " |-- ln_tr_exp: integer (nullable = true)\n",
      " |-- investornameshort: string (nullable = true)"
     ]
    }
   ],
   "source": [
    "%%spark\n",
    "\n",
    "preprocessed_month_data.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "%%spark\n",
    "\n",
    "def predict(model_pipeline, data):\n",
    "    \n",
    "    _scoreUdf = udf(lambda v: float(v[1]), DoubleType())\n",
    "    \n",
    "    prediction = model_pipeline.transform(data)\n",
    "    pred_df = prediction.withColumn('pred', _scoreUdf(prediction['probability']))\n",
    "    return pred_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "%%spark\n",
    "\n",
    "def fullMonthPrediction_pur_ex(df, model_pipeline_lr, model_pipeline_rf, model_pipeline_gbt):\n",
    "    \n",
    "    _scoreUdf = F.udf(lambda v: float(v[1]), T.DoubleType())\n",
    "    \n",
    "    predictionsLR = model_pipeline_lr.transform(df)\n",
    "    pred_df_lr = predictionsLR.withColumn('pred', _scoreUdf(predictionsLR['probability']))\\\n",
    "                                .select('ln_no', 'og_note_dt', col('pred').alias('logRegProb'))\n",
    "    \n",
    "    predictionsRF = model_pipeline_rf.transform(df)\n",
    "    pred_df_rf = predictionsRF.withColumn('pred', _scoreUdf(predictionsRF['probability']))\\\n",
    "                                .select('ln_no', col('pred').alias('randForProb'))\n",
    "    \n",
    "    predictionsGBT = model_pipeline_gbt.transform(df)\n",
    "    pred_df_gbt = predictionsGBT.withColumn('pred', _scoreUdf(predictionsGBT['probability']))\\\n",
    "                                .select('ln_no', col('pred').alias('gbtProb'))\n",
    "    \n",
    "    combinedFinalPred = pred_df_lr.join(pred_df_rf, on='ln_no', how='left')\\\n",
    "                                    .join(pred_df_gbt, on='ln_no', how='left')\\\n",
    "                                    .dropDuplicates()\n",
    "    \n",
    "    return combinedFinalPred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "%%spark\n",
    "\n",
    "def dedup_result_pred_pur_ex(pred_df):\n",
    "    \n",
    "    pred_df_dedup = pred_df.groupby('ln_no', 'og_note_dt')\\\n",
    "                            .agg(F.avg('logRegProb').alias('logRegProb'),\n",
    "                                 F.avg('randForProb').alias('randForProb'),\n",
    "                                 F.avg('gbtProb').alias('gbtProb')\n",
    "                            )\n",
    "\n",
    "    return pred_df_dedup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "%%spark\n",
    "\n",
    "def save_csv_pur(df_prep, model_pipeline_lr, model_pipeline_rf, model_pipeline_gbt, filename, result_path):\n",
    "    \n",
    "    pred = fullMonthPrediction_pur_ex(df_prep, model_pipeline_lr, model_pipeline_rf, model_pipeline_gbt)\n",
    "    dedup = dedup_result_pred_pur_ex(pred)\n",
    "    \n",
    "    dedup.coalesce(1).write.csv(result_path + filename, header=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### (3). 3-6 Months"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "#### 2020"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "%%spark\n",
    "\n",
    "# 2020-01\n",
    "save_csv_pur(preprocessed_month_data, \n",
    "             model_pipeline_lr_6, model_pipeline_rf_6, model_pipeline_gbt_6,\n",
    "             'pred_Mover_3to6_V1_jan20_20200203.csv', \n",
    "             result_path_pur_6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "%%spark\n",
    "\n",
    "# 2020-02\n",
    "save_csv_pur(preprocessed_month_data, \n",
    "             model_pipeline_lr_6, model_pipeline_rf_6, model_pipeline_gbt_6,\n",
    "             'pred_Mover_3to6_V1_feb20_20200305.csv', \n",
    "             result_path_pur_6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "%%spark\n",
    "\n",
    "# 2020-03\n",
    "save_csv_pur(preprocessed_month_data, \n",
    "             model_pipeline_lr_6, model_pipeline_rf_6, model_pipeline_gbt_6,\n",
    "             'pred_Mover_3to6_V1_mar20_20200406.csv', \n",
    "             result_path_pur_6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "%%spark\n",
    "\n",
    "# 2020-04\n",
    "save_csv_pur(preprocessed_month_data, \n",
    "             model_pipeline_lr_6, model_pipeline_rf_6, model_pipeline_gbt_6,\n",
    "             'pred_Mover_3to6_V1_apr20_20200505.csv', \n",
    "             result_path_pur_6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "%%spark\n",
    "\n",
    "# 2020-05\n",
    "save_csv_pur(preprocessed_month_data, \n",
    "             model_pipeline_lr_6, model_pipeline_rf_6, model_pipeline_gbt_6,\n",
    "             'pred_Mover_3to6_V1_1_may20_20200610.csv', \n",
    "             result_path_pur_6)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "source": [
    "### (4). 6-12 Months"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "source": [
    "#### 2020"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "%%spark\n",
    "\n",
    "# 2020-01\n",
    "save_csv_pur(preprocessed_month_data, \n",
    "             model_pipeline_lr_12, model_pipeline_rf_12, model_pipeline_gbt_12,\n",
    "             'pred_Mover_6to12_V1_jan20_20200203.csv', \n",
    "             result_path_pur_12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "%%spark\n",
    "\n",
    "# 2020-02\n",
    "save_csv_pur(preprocessed_month_data, \n",
    "             model_pipeline_lr_12, model_pipeline_rf_12, model_pipeline_gbt_12,\n",
    "             'pred_Mover_6to12_V1_feb20_20200305.csv', \n",
    "             result_path_pur_12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "%%spark\n",
    "\n",
    "# 2020-03\n",
    "save_csv_pur(preprocessed_month_data, \n",
    "             model_pipeline_lr_12, model_pipeline_rf_12, model_pipeline_gbt_12,\n",
    "             'pred_Mover_6to12_V1_mar20_20200406.csv', \n",
    "             result_path_pur_12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "%%spark\n",
    "\n",
    "# 2020-04\n",
    "save_csv_pur(preprocessed_month_data, \n",
    "             model_pipeline_lr_12, model_pipeline_rf_12, model_pipeline_gbt_12,\n",
    "             'pred_Mover_6to12_V1_apr20_20200505.csv', \n",
    "             result_path_pur_12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "%%spark\n",
    "\n",
    "# 2020-05\n",
    "save_csv_pur(preprocessed_month_data, \n",
    "             model_pipeline_lr_12, model_pipeline_rf_12, model_pipeline_gbt_12,\n",
    "             'pred_Mover_6to12_V1_1_may20_20200610.csv', \n",
    "             result_path_pur_12)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "source": [
    "## 7. Compile Mover Purchase Model Results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### (1). Compile Monthly Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "%%spark\n",
    "\n",
    "def compile_scores(scorefile_3, scorefile_6, scorefile_12):\n",
    "    \n",
    "    df_gcid = spark.sql('select * from data_science_sandbox.gcidservicingloans')\n",
    "    \n",
    "    score_3 = spark.read.csv(result_path_pur + scorefile_3, header=True)\\\n",
    "                    .select('ln_no', \n",
    "                            col('gbtProb').cast('double').alias('score_0_3mo'))\n",
    "    score_6 = spark.read.csv(result_path_pur_6 + scorefile_6, header=True)\\\n",
    "                    .select('ln_no', \n",
    "                            col('og_note_dt').substr(1, 10).alias('origination_date'),\n",
    "                            col('gbtProb').cast('double').alias('score_3_6mo'))\n",
    "    score_12 = spark.read.csv(result_path_pur_12 + scorefile_12, header=True)\\\n",
    "                    .select('ln_no', col('gbtProb').cast('double').alias('score_6_12mo'))\n",
    "        \n",
    "    score_all = score_3.join(score_6, on='ln_no', how='inner')\\\n",
    "                        .join(score_12, on='ln_no', how='inner')\n",
    "        \n",
    "    ls = []\n",
    "    for score in ['score_0_3mo', 'score_3_6mo', 'score_6_12mo']:\n",
    "        ls.extend(statFunc(score_all).approxQuantile(score, [0.7, 0.85, 0.95], 0.00001))\n",
    "        \n",
    "    # Top 5% of score_0_3mo are Mover\n",
    "    # Remaining of top 15% of score_3_6mo are Searcher (~10%)\n",
    "    # Remaining of top 30% of score_6_12mo are Thinker (~15%)\n",
    "    expr_type = when(col('score_0_3mo') >= ls[2], 'Mover')\\\n",
    "                    .otherwise(\n",
    "                        when(col('score_3_6mo') >= ls[4], 'Searcher')\\\n",
    "                            .otherwise(\n",
    "                                when(col('score_6_12mo') >= ls[6], 'Thinker')\\\n",
    "                                    .otherwise('Other')\n",
    "                            )\n",
    "                    )\n",
    "\n",
    "    score_all = score_all.withColumn('type', expr_type)\\\n",
    "                            .join(df_gcid, score_all.ln_no == df_gcid.Loannumber, how='left')\n",
    "    \n",
    "    return score_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "%%spark\n",
    "\n",
    "def score_save(scorefile_3, scorefile_6, scorefile_12, servicedate, filename):\n",
    "    \n",
    "    score_df = compile_scores(scorefile_3, scorefile_6, scorefile_12)\n",
    "    \n",
    "    df1 = score_df.withColumn('servicecalendardate', lit(servicedate))\\\n",
    "                    .select('servicecalendardate', 'ln_no', 'GCID', 'origination_date', \n",
    "                            'type', 'score_0_3mo', 'score_3_6mo', 'score_6_12mo')\n",
    "    \n",
    "    df1.coalesce(1).write.csv(result_path_pur_all + filename, header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "%%spark\n",
    "\n",
    "score_save(\n",
    "    scorefile_3 = 'pred_MoverV3_3_may20_20200610.csv',\n",
    "    scorefile_6 = 'pred_Mover_3to6_V1_1_may20_20200610.csv',\n",
    "    scorefile_12 = 'pred_Mover_6to12_V1_1_may20_20200610.csv',\n",
    "    servicedate = '2020-05-31',\n",
    "    filename = 'pred_Mover_Pur_All_may20_20200610.csv'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### (2). Insert into the table for Dashboard for Nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "%%spark\n",
    "\n",
    "# t1 = spark.read.csv(result_path_pur_all + 'pred_Mover_Pur_All_mar20_20200406.csv', header=True).withColumnRenamed('ln_no', 'loan')\n",
    "\n",
    "# print(t1.count())\n",
    "# t1.show(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "%%spark\n",
    "\n",
    "# t1.groupby('type').count().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%%spark\n",
    "\n",
    "# First snapshot: 10/31/2019\n",
    "# Going forward, insert into the table, instead of overwriting.\n",
    "\n",
    "# t1.write.mode('append').saveAsTable('Analytical.wol_dashboard_serviced_purchase_v1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "%%spark\n",
    "\n",
    "# df = spark.sql('''\n",
    "# select *\n",
    "# from Analytical.wol_dashboard_serviced_purchase_v1\n",
    "# ''')\n",
    "\n",
    "# df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "source": [
    "## 8. Save Results into Prod Path"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### (1). Save Model Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1889579\n",
      "1889579\n",
      "+----------+------------------+\n",
      "|      loan|             score|\n",
      "+----------+------------------+\n",
      "|3433101386|0.6133600376423959|\n",
      "+----------+------------------+\n",
      "only showing top 1 row\n",
      "\n",
      "+----------+-----------------+\n",
      "|      loan|            score|\n",
      "+----------+-----------------+\n",
      "|3429917877|0.262411623881287|\n",
      "+----------+-----------------+\n",
      "only showing top 1 row"
     ]
    }
   ],
   "source": [
    "%%spark\n",
    "\n",
    "## download pred_refiV1_3_oct19_20191105.csv and pred_MoverV3_2_oct19_20191105.csv, upload on DW, let Lu do the rest\n",
    "# result_path_refi = '/dev/projects/retention_models/refi_payoff/training/results/'\n",
    "# result_path_pur = '/dev/projects/retention_models/purchase_payoff/training/results/movermodel/'\n",
    "\n",
    "score_refi = spark.read.csv(result_path_refi + 'pred_refiV1_4_may20_20200610.csv', header=True)\\\n",
    "                    .select(col('ln_no').alias('loan'), col('gbtProb').alias('score'))\n",
    "        \n",
    "score_pur = spark.read.csv(result_path_pur + 'pred_MoverV3_3_may20_20200610.csv', header=True)\\\n",
    "                    .select(col('ln_no').alias('loan'), col('gbtProb').alias('score'))\n",
    "\n",
    "print(score_refi.count())\n",
    "print(score_pur.count())\n",
    "\n",
    "score_refi.show(1)\n",
    "score_pur.show(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "%%spark\n",
    "\n",
    "## use snapshotdate in the file name\n",
    "score_refi.coalesce(1).write.csv(prod_refi_path + 'leadgen_servicing_mover_refi_20200610.csv', header=True)\n",
    "score_pur.coalesce(1).write.csv(prod_pur_path + 'leadgen_servicing_mover_pur_20200610.csv', header=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### (2). Save score path, and update with new version model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------------------------------------------------------------------------------------------------+\n",
      "|filepath                                                                                                      |\n",
      "+--------------------------------------------------------------------------------------------------------------+\n",
      "|/prod/projects/model_conformed/RocketScience/LeadGen/RefiLeadGen/1.0/leadgen_servicing_mover_refi_20200610.csv|\n",
      "+--------------------------------------------------------------------------------------------------------------+\n",
      "\n",
      "+------------------------------------------------------------------------------------------------------------+\n",
      "|filepath                                                                                                    |\n",
      "+------------------------------------------------------------------------------------------------------------+\n",
      "|/prod/projects/model_conformed/RocketScience/LeadGen/PurLeadGen/1.0/leadgen_servicing_mover_pur_20200610.csv|\n",
      "+------------------------------------------------------------------------------------------------------------+"
     ]
    }
   ],
   "source": [
    "%%spark\n",
    "\n",
    "refi_file = spark.createDataFrame([('/prod/projects/model_conformed/RocketScience/LeadGen/RefiLeadGen/1.0/leadgen_servicing_mover_refi_20200610.csv',)], ['filepath'])\n",
    "pur_file = spark.createDataFrame([('/prod/projects/model_conformed/RocketScience/LeadGen/PurLeadGen/1.0/leadgen_servicing_mover_pur_20200610.csv',)], ['filepath'])\n",
    "\n",
    "refi_file.show(10, False)\n",
    "pur_file.show(10, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "%%spark\n",
    "\n",
    "# Before running, delete the two csv files in Ambari.\n",
    "file_path = '/prod/projects/model_conformed/RocketScience/LeadGen/Currentfile/'\n",
    "\n",
    "refi_file.coalesce(1).write.csv(file_path + 'current_leadgen_servicing_mover_refi.csv', header=True)\n",
    "pur_file.coalesce(1).write.csv(file_path + 'current_leadgen_servicing_mover_pur.csv', header=True)\n",
    "\n",
    "## save these two files and let BV do the rest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "source": [
    "# Actual"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "%%spark\n",
    "\n",
    "from pyspark.sql.functions import lower\n",
    "\n",
    "csv_path = '/dev/projects/retention_models/csv_data/'\n",
    "actual_path = '/dev/projects/retention_models/actual_value/'\n",
    "monthly_path = '/dev/projects/retention_models/monthly_snapshot/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "%%spark\n",
    " \n",
    "df_actual = spark.read.csv(csv_path + 'Payoff_segments_summary_20191206.csv', header=True)\\\n",
    "                        .withColumn('newloanpurpose', lower(col('NewLoanPurpose')))\\\n",
    "                        .withColumn('retentiontype', lower(col('PayoffRetentionType')))\\\n",
    "                        .select('ServicedLoanNumber', 'PaymentInFullDate', 'newloanpurpose', 'retentiontype')\n",
    "    \n",
    "df_list1 = spark.sql('''\n",
    "select distinct servicecalendardate, ln_no\n",
    "from data_science_sandbox.servicing_dbo_payoff_source_purchase_client_crdtrs \n",
    "where leftportfoliodate is null\n",
    "and servicecalendardate between '2016-06-30' and '2018-11-30'\n",
    "''')\n",
    "\n",
    "## upload from DW table\n",
    "\n",
    "df_201812 = spark.read.parquet(monthly_path+'servicing_df_all_dec18_20190131.parquet').select('servicecalendardate', 'ln_no')\n",
    " \n",
    "df_201901 = spark.read.parquet(monthly_path+'servicing_df_all_jan19_20190215.parquet').select('servicecalendardate', 'ln_no')\n",
    "df_201902 = spark.read.parquet(monthly_path+'servicing_df_all_feb19_20190305.parquet').select('servicecalendardate', 'ln_no')\n",
    "df_201903 = spark.read.parquet(monthly_path+'servicing_df_all_mar19_20190409.parquet').select('servicecalendardate', 'ln_no')\n",
    "df_201904 = spark.read.parquet(monthly_path+'servicing_df_all_apr19_20190507.parquet').select('servicecalendardate', 'ln_no')\n",
    "df_201905 = spark.read.parquet(monthly_path+'servicing_df_all_may19_20190610.parquet').select('servicecalendardate', 'ln_no')\n",
    "df_201906 = spark.read.parquet(monthly_path+'servicing_df_all_june19_20190708.parquet').select('servicecalendardate', 'ln_no')\n",
    "df_201907 = spark.read.parquet(monthly_path+'servicing_df_all_jul19_20190805.parquet').select('servicecalendardate', 'ln_no')\n",
    "df_201908 = spark.read.parquet(monthly_path+'servicing_df_all_aug19_20190904.parquet').select('servicecalendardate', 'ln_no')\n",
    "df_201909 = spark.read.parquet(monthly_path+'servicing_df_all_sep19_20191004.parquet').select('servicecalendardate', 'ln_no')\n",
    "df_201910 = spark.read.parquet(monthly_path+'servicing_df_all_oct19_20191105.parquet').select('servicecalendardate', 'ln_no')\n",
    "df_201911 = spark.read.parquet(monthly_path+'servicing_df_all_nov19_20191202.parquet').select('servicecalendardate', 'ln_no')\n",
    "\n",
    " \n",
    "df_list = df_list1.union(df_201812)\\\n",
    "                    .union(df_201901).union(df_201902).union(df_201903)\\\n",
    "                    .union(df_201904).union(df_201905).union(df_201906)\\\n",
    "                    .union(df_201907).union(df_201908).union(df_201909)\\\n",
    "                    .union(df_201910).union(df_201911)\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "%%spark\n",
    "\n",
    "df_payoff = df_list.join(df_actual, df_actual.ServicedLoanNumber == df_list.ln_no, how='left')\n",
    " \n",
    "def build_targets(df):\n",
    "    \n",
    "    # Purchase Payoff\n",
    "    expr_purpayoff = when((col('PaymentInFullDate')>col('startdt')) & (col('PaymentInFullDate')<=col('enddt_3')) & (col('newloanpurpose')=='purchase'), 1.)\\\n",
    "                        .otherwise(0.)\n",
    "    expr_purpayoff_3_6 = when((col('PaymentInFullDate')>col('enddt_3')) & (col('PaymentInFullDate')<=col('enddt_6')) & (col('newloanpurpose')=='purchase'), 1.)\\\n",
    "                            .otherwise(0.)\n",
    "    expr_purpayoff_6_12 = when((col('PaymentInFullDate')>col('enddt_6')) & (col('PaymentInFullDate')<=col('enddt_12')) & (col('newloanpurpose')=='purchase'), 1.)\\\n",
    "                            .otherwise(0.)\n",
    "    expr_purpayoff_all = when((col('PaymentInFullDate')>col('servicecalendardate')) & (col('newloanpurpose')=='purchase'), 1.)\\\n",
    "                            .otherwise(0.)\n",
    "    \n",
    "    # Refi Payoff\n",
    "    expr_refipayoff = when((col('PaymentInFullDate')>col('startdt')) & (col('PaymentInFullDate')<=col('enddt_3')) & (col('newloanpurpose')!='purchase'), 1.)\\\n",
    "                        .otherwise(0.)\n",
    "    expr_refipayoff_all = when((col('PaymentInFullDate')>col('servicecalendardate')) & (col('newloanpurpose')!='purchase'), 1.)\\\n",
    "                            .otherwise(0.)\n",
    "    \n",
    "    # Purchase/Refi Retained\n",
    "    expr_purretain_24 = when((col('PaymentInFullDate')>col('startdt')) & (col('PaymentInFullDate')<=col('enddt_24')) \n",
    "                             & (col('newloanpurpose')=='purchase') & (col('retentiontype')=='retained'), 1.)\\\n",
    "                            .otherwise(0.)\n",
    "    \n",
    "    expr_refiretain_24 = when((col('PaymentInFullDate')>col('startdt')) & (col('PaymentInFullDate')<=col('enddt_24')) \n",
    "                             & (col('newloanpurpose')!='purchase') & (col('retentiontype')=='retained'), 1.)\\\n",
    "                            .otherwise(0.)\n",
    "    \n",
    "    # Payoff\n",
    "    expr_payoff = when((col('PaymentInFullDate')>col('startdt')) & (col('PaymentInFullDate')<=col('enddt_3')), 1.)\\\n",
    "                        .otherwise(0.)\n",
    "    expr_payoff_24 = when((col('PaymentInFullDate')>col('startdt')) & (col('PaymentInFullDate')<=col('enddt_24')), 1.)\\\n",
    "                        .otherwise(0.)\n",
    "    expr_payoff_all = when(col('PaymentInFullDate')>col('servicecalendardate'), 1.)\\\n",
    "                        .otherwise(0.)\n",
    "    \n",
    "    # Retained\n",
    "    expr_retention = when((col('PaymentInFullDate')>col('startdt')) & (col('PaymentInFullDate')<=col('enddt_3')) & (col('retentiontype')=='retained'), 1.)\\\n",
    "                        .otherwise(0.)\n",
    "    expr_retention_3_6 = when((col('PaymentInFullDate')>col('enddt_3')) & (col('PaymentInFullDate')<=col('enddt_6')) & (col('retentiontype')=='retained'), 1.)\\\n",
    "                            .otherwise(0.)\n",
    "    expr_retention_6_12 = when((col('PaymentInFullDate')>col('enddt_6')) & (col('PaymentInFullDate')<=col('enddt_12')) & (col('retentiontype')=='retained'), 1.)\\\n",
    "                            .otherwise(0.)\n",
    "    expr_retention_24 = when((col('PaymentInFullDate')>col('startdt')) & (col('PaymentInFullDate')<=col('enddt_24')) & (col('retentiontype')=='retained'), 1.)\\\n",
    "                        .otherwise(0.)\n",
    "    expr_retention_all = when((col('PaymentInFullDate')>col('servicecalendardate')) & (col('retentiontype')=='retained'), 1.)\\\n",
    "                        .otherwise(0.)\n",
    " \n",
    "    df_final = df.withColumn('startdt', F.add_months(col('servicecalendardate'), 1))\\\n",
    "                    .withColumn('enddt_3', F.add_months(col('servicecalendardate'), 4))\\\n",
    "                    .withColumn('enddt_6', F.add_months(col('servicecalendardate'), 7))\\\n",
    "                    .withColumn('enddt_12', F.add_months(col('servicecalendardate'), 13))\\\n",
    "                    .withColumn('enddt_24', F.add_months(col('servicecalendardate'), 25))\\\n",
    "                    .withColumn('purchasepayoff', expr_purpayoff)\\\n",
    "                    .withColumn('purchasepayoff_3_6', expr_purpayoff_3_6)\\\n",
    "                    .withColumn('purchasepayoff_6_12', expr_purpayoff_6_12)\\\n",
    "                    .withColumn('purchasepayoff_all', expr_purpayoff_all)\\\n",
    "                    .withColumn('refipayoff', expr_refipayoff)\\\n",
    "                    .withColumn('refipayoff_all', expr_refipayoff_all)\\\n",
    "                    .withColumn('purretain_24', expr_purretain_24)\\\n",
    "                    .withColumn('refiretain_24', expr_refiretain_24)\\\n",
    "                    .withColumn('payoff', expr_payoff)\\\n",
    "                    .withColumn('payoff_24', expr_payoff_24)\\\n",
    "                    .withColumn('payoff_all', expr_payoff_all)\\\n",
    "                    .withColumn('retained', expr_retention)\\\n",
    "                    .withColumn('retained_3_6', expr_retention_3_6)\\\n",
    "                    .withColumn('retained_6_12', expr_retention_6_12)\\\n",
    "                    .withColumn('retained_24', expr_retention_24)\\\n",
    "                    .withColumn('retained_all', expr_retention_all)\\\n",
    "                    .select('servicecalendardate', 'ln_no', 'PaymentInFullDate', 'newloanpurpose', 'retentiontype',\n",
    "                            'purchasepayoff', 'purchasepayoff_3_6', 'purchasepayoff_6_12', 'purchasepayoff_all',\n",
    "                            'refipayoff', 'refipayoff_all', \n",
    "                            'purretain_24', 'refiretain_24',\n",
    "                            'payoff', 'payoff_24', 'payoff_all', \n",
    "                            'retained', 'retained_3_6', 'retained_6_12', 'retained_24', 'retained_all')\n",
    "                        \n",
    "    return df_final\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "%%spark\n",
    "\n",
    "df_final = build_targets(df_payoff)\n",
    " \n",
    "df_final.write.parquet(actual_path + 'Actual_payoff_20191206.parquet', mode='overwrite')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Check the count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "%%spark\n",
    "\n",
    "df1 = spark.read.parquet(actual_path + 'Actual_payoff_20191106.parquet')\n",
    "df1.groupBy('servicecalendardate').count().sort(desc(\"servicecalendardate\")).show(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "%%spark\n",
    "\n",
    "df2 = spark.read.parquet(actual_path + 'Actual_payoff_20191206.parquet')\n",
    "df2.groupBy('servicecalendardate').count().sort(desc(\"servicecalendardate\")).show(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "%%spark\n",
    "\n",
    "df1.show(1)\n",
    "df2.show(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python3.5 with Watson Studio Spark 2.2.1",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
